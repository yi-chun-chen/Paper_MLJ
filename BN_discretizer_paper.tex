%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[round]{natbib}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{lscape}
\usepackage{caption}
\usepackage{siunitx}
\usepackage{booktabs}
% \usepackage[capitalize]{cleveref}
\usetikzlibrary{bayesnet}
\setcitestyle{aysep={ }} %Author-Year Separator
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CUSTOM COMMANDS

\newcommand{\bigo}{\mathcal{O}} % NOTE(tim): if you prefer normal O change it here.

\newcommand{\paren}[1]{\mathopen{}\mathclose\bgroup\left(#1\aftergroup\egroup\right)}
\newcommand{\brock}[1]{\mathopen{}\mathclose\bgroup\left[#1\aftergroup\egroup\right]}
\newcommand{\curly}[1]{\mathopen{}\mathclose\bgroup\left\{#1\aftergroup\egroup\right\}}
\newcommand{\anglebrackets}[1]{\langle #1 \rangle}
\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}

\newcommand{\discset}{\mathcal{M}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\todo}[1]{\textcolor{magenta}{#1}}
\newcommand{\tim}[1]{\textit{\textcolor{blue}{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Learning Discrete-valued Bayesian Networks from Mixed Data%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Yi-Chun Chen           \and
        Tim A. Wheeler         \and
        Mykel J. Kochenderfer
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{F. Author \at
              first address \\
              Tel.: +123-45-678910\\
              Fax: +123-45-678910\\
              \email{fauthor@example.com}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           S. Author \at
              second address
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
\todo{
Insert your abstract here. Include keywords, PACS and mathematical
subject classification numbers as needed.
}
\keywords{Discretization \and Bayesian Network \and Continuous Variable}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{intro}
Bayesian networks \citep{Pearl_1988, PGM_2009} are an increasingly popular method for modeling uncertainty and causality in science and engineering. They provide an efficient factorization of the joint probability distribution over a set of random variables. Bayesian networks first emerged from artificial intelligence research and have been applied to a wide variety of problems, ranging from decision-making systems \citep{DMU_2015} to medical diagnoses \citep{Lustgarten_2011}. In most cases, we assume that all random variables in Bayesian networks are discrete, since many Bayesian network learning algorithms are unable to deal with continuous variables efficiently. However, many applications
require the use of continuous variables, such as position and velocity in dynamic systems.

There are two common approaches to extending Bayesian networks to continuous variables.
The first is to model the conditional probability density of each continuous variable using specific families of parametric distributions, and then to redesign Bayesian network learning algorithms based on their parameters.
One successful example is belief propagation in Gaussian graphical models \citep{Weiss_2011}.
For other parametric distributions \citep{Ihler_2009} and non-linear functions~\todo{[cite]}, these redesigned algorithms are computationally expensive and do not perform well.

The second approach is discretization.
Automated discretization methods have been studied in machine learning and statistics for many years \citep{Dougherty_1995, Kerber_1992, Holte_1993, Fayyad_1993}, primarily for classification problems.
They search for the best discretization policy of a continuous attribute by considering its interation with the target class variable.
Interations and dependencies between variables in Bayesian networks are more complicated, where discretization requires considering the impact on the variable's Markov blanket.
Prior work exists for discretizing continuous variables in naive Bayesian networks and tree-augmented networks \citep{Fried_naive}, but only a few discretization methods for general Bayesian networks have been proposed \citep{Friedman_1996, Kozlov_1997, Monti_1998, Steck_2007}.

This paper describes a new Bayesian discretization method for continuous variables in Bayesian networks, extending prior work on single-variable discretization methods from \citet{Boulle_2006} and \citet{Lustgarten_2011}.
The proposed method optimizes the discretization policy relative to the network and takes parents, children, and spouse variables into account.
The optimal single-variable discretization method is derived in Section \ref{sec:single_var}, and a second heuristic method is proposed which reduces the runtime from exponential to polynomial.
Section \ref{sec:multi_var} covers Bayesian networks with multiple continuous variables and discretization while simultaneously learning network structure.
The paper concludes with a comparison against the existing minimum-description length \citep{Friedman_1996} method on real-world datasets in Section \ref{sec:experiments}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{sec:related_work}
This section reviews the minimum description length (MDL) principle discretization \citep{Friedman_1996} and MODL discretization \citep{Boulle_2006} methods.
The former is the predominant discretization method for continuous variables in Bayesian networks, and is compared to our proposed method in Section \ref{sec:experiments}.
The latter is a discretization method for one continuous variable against a discrete target class, which our proposed method generalizes to Bayesian networks.
The asymptotical equivalence between MDL and MODL was examined in \citep{VL_2000}.

\subsection{MDL Principle Discretization}
The MDL principle was first proposed by \cite{MDL_1978}, and states that the best model for a dataset is one which minimizes the amount of information needed to describe it \citep{Grunwald_2009}.
MDL methods trade off goodness-of-fit against model complexity to reduce generalization error.
In the context of Bayesian networks, \cite{Friedman_1996} applied the MDL principle to determine the optimal number of discretization intervals for continuous variables and optimal the positions of their discretization boundaries.
Their approach selects a discretization policy that minimizes the sum of the description lengths of the discretized Bayesian network and the information necessary for recovering the continuous values from the discretized data.
In the single continuous variable case, the objective function is

% \begin{small}
\begin{equation}
\begin{aligned}
\frac{1}{2} \log(N) \left\lbrace  \lvert \Pi_{X_i} \rvert (\lvert X^*_i \rvert - 1) +
 {\sum_{j,X_i \in \Pi_{X_i}}} \lvert \Pi_{X^*_j} \rvert (\lvert X_j \rvert - 1) \right\rbrace + \log(\lvert {X^*_i} \rvert) \\
 + (N_i-1) H \left( {{|X^*_i| - 1}\over{N_i -1}}  \right) -N \cdot \left[ I(X^*_i,\Pi_{X_i}) + {\sum_{j,X_i \in \Pi_{X_i}}} I(X_j, \Pi_{X^*_j}) \right],
\end{aligned}
\end{equation}
% \end{small}

\noindent
% $I(\boldsymbol{A},\boldsymbol{B}) =  \sum_{\boldsymbol{a},\boldsymbol{b}} \hat{P}_D (\boldsymbol{a},\boldsymbol{b}) \log {{\hat{P}_D (\boldsymbol{a},\boldsymbol{b})}\over{\hat{P}_D (\boldsymbol{a}),\hat{P}_D (\boldsymbol{b})}}$
where $I(\boldsymbol{A},\boldsymbol{B})$ is the mutual information between the discrete variables $\boldsymbol{A}$ and $\boldsymbol{B}$, ${H(p) = -p \log(p) - (1-p) \log(1-p)}$, $|\boldsymbol{X}|$ is the cardinality of discrete variable $\boldsymbol{X}$, and $X^*_i$ is the discretized version of the $i$th sample of continuous variable $X$.
The optimal discretization policy can be found with dynamical programming.
For Bayesian networks with multiple continuous variables, the algorithm is applied to one variable at a time iteratively over all continuous variables.
While iterating, only one variable is treated as continuous and other continuous variables are discretized based on an initial discretization policy or the discretization result from a previous iteration.

The network structure is not always known in advance. Bayesian network structure learning can be extended to distributions including continuous variables by alternating between traditional discrete structure learning and optimal discretization. Starting with some preliminary discretization policy, one applys a structure learning algorithm to identify the locally optimal graph structure. The discretization policy is refined based on the learned network. The cycle is continued until convergence.

% The discretization technique proposed by \citet{Friedman_1996} is the most well-known of these methods. It is based on the minimum description length principle (MDL): the optimal discretization policy minimizes the description length of the Bayesian network and discretization policy. The MDL algorithm has a $\bigo\paren{N^3 + \paren{n_c {v_\text{max}}^{(n_c^p)_\text{max}} + {v_\text{max}}^{n_p}} \cdot N^2}$ runtime on Bayesian networks with a single continuous variable and multiple discrete variables, where $N$ is the number of data samples from the joint distribution, $n_p$ and $n_c$ are the numbers of parent and children variables for the continuous variable, $v_\text{max}$ is the largest cardinality over all variables in the Markov blanket, and  ${(n_c^p)_\text{max}}$ is the largest number of parent variables of the continuous variable's children. The MDL method iterates over all continuous variables until convergence in the case of multiple continuous variables, converging in a few cycles according to our tests of real-world data. Unfortunately, MDL tends to produce discrete variables with low cardinality~\todo{[cite]}.

\subsection{MODL Discretization}
MODL discretization \citep{Boulle_2006} is a Bayesian method for discretizing a continuous feature according to a class variable. Bayesian methods maximize the probability of the model given the data, $P(\textit{Model} \mid \textit{Data})$. An application of Bayes' rule and constant $P(\textit{Data})$ shows that this is equivalent to maximizing:
\begin{align}
P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model})\text{,}
\end{align}

\noindent
where $P(\textit{Model})$ is a prior over models and ${P(\textit{Data} \mid \textit{Model})}$ is the data likelihood.
The data likelihood usually increases with the number of discretization intervals, as more intervals allow for richer representations.
The prior decreases as the number of discretization intervals increases to favor simpler models and prevent overfitting.
Maximizing ${P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model})}$ requires a trade-off when determining the number of discretization intervals.

The MODL method uses dynamic programming to find the optimal discretization policy, and has a $\bigo\paren{N^3 + |\text{Class}| \cdot N^2}$ runtime, where $N$ is the of number of data instances.
\cite{Lustgarten_2011} suggest several formulations for the prior term $P(\text{Model})$.
Under a uniform prior probability over discretizations the runtime can be reduced to $\bigo\paren{|\text{Class}| \cdot N^2}$ without sacrificing optimality.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}
\label{sec:preliminaries}
This section provides a brief overview of Bayesian networks, including the factorization of joint probability distributions, sampling from a Bayesian network, and structure learning. These concepts will be used in later sections. The formal definition of a discretization policy for a continuous variable is also given.

\subsection{Bayesian Networks and Structure Learning}

A Bayesian network $B$ is defined by a pair $(G,\Theta)$, where $G = (X,E)$ is a directed acyclic graph whose nodes correspond to a set of random variables $X = \brock{X_1, X_2, \cdots, X_n}$, and whose edges $E$ represent probabilistic dependencies among nodes. The graph structure $G$ encodes the Markov property: each node $X_i$ is independent of its non-descendants given its parents $\Pi_{X_i}$ in $G$. The conditional relations are parameterized by the elements of $\Theta$, which take the form $\theta_{x_i \mid \Pi_{x_i}} = P(x_i \mid \Pi_{x_i})$ for each possible value $x_i$ of $X_i$, and $\Pi_{x_i}$ of $\Pi_{X_i}$. The joint distribution over $X$ factors according to the Markov property:
\begin{equation}
P_B (X_1 , \cdots, X_n) = \prod_{i=1}^{n} P_B (X_i \mid \Pi_{X_i}) = \prod_{i=1}^{n} \theta_{x_i \mid \Pi_{x_i}}\text{.}
\end{equation}

Forward sampling is used to draw samples from the joint distribution represented by a Bayesian network.
Variables are sampled in topological order such that parental instantiations are always known~\citep[see][chap.~22]{algo_2009}.
Furthermore, the parent $\rightarrow$ child sampling order can be reversed if the marginal probability of the child variable is known.
By Bayes' rule,

\begin{equation}
P(X_i \mid \Pi_{X_i}) \cdot \prod_{j = 1}^{ Pa( X_i)} P( \{ \Pi_{X_i} \}_j) = P(X_i) \cdot P(\Pi_{X_i} \mid X_i),
\end{equation}

\noindent
where $Pa(X_i)$ is the number of parents of $X_i$ and $\brock{\Pi_{X_i}}_j$ is the $j$th parent of $X_i$.
% One can first sample $X_i$ by $P(X_i)$, then sample all the parent variables simultaneously by $P(\Pi_{X_i} \mid X_i)$. That is to say, $X_i$ becomes the starting point of sampling.

It is often necessary to infer the structure of a Bayesian network from data.
Three common approaches to Bayesian network structure learning are constraint-based, score-based, and Bayesian model averaging \citep[see][chap.~18]{PGM_2009}. This work uses the K2 structure learning algorithm \citep{K2}, one of the most successful score-based structure learning methods.
Score-based structure learning methods over discrete variables commonly evaluate candidate structures according to their likelihood, $\prod_i f(X_i, \Pi_{X_i})$, where

\begin{align}
f(X_i, \Pi_{X_i}) = \prod_{j=1}^{|\Pi_{X_i}|} {{(|X_i|-1)!}\over{(N_{ij} + |X_i|-1)!}} \prod_{k=1}^{|X_i|} \alpha_{ijk}!\text{,}
\end{align}

\noindent
where $|X_i|$ is the cardinality of $X_i$, $|\Pi_{X_i}|$ is number of possible instantiations of the parent variables of $X_i$, $\alpha_{ijk}$ is the number of instances of the $k$th value of $X_i$ with the $j$th parental instantiation, and $N_{ij} = \sum_{k=1}^{|X_i|} \alpha_{ijk}$.
The optimal structure is the most probably structure given the data.
The space of acyclic graphcs is superexponential in the number of nodes so it is common to rely on heuristic search strategies \citep{PGM_2009}.

The K2 algorithm assumes a topological ordering of variables and greedily adds parents to nodes to maximally increase the likelihood score.
A fixed ordering ensures acyclicity but does not guarantee a globally optimal network structure.
K2 is typically run multiple times with random variable orderings and the network with the highest likelihood is retained.

\subsection{Discretization Policies}

A discretization policy $M_C = \anglebrackets{t_1 < t_2 < \ldots < t_{k-1}}$ for a continuous variable $C$ is a mapping from !!! mathbb{R} !!! to $\brock{1,2,3,\ldots,k}$ such that
\begin{equation}
  M_C (x)=\begin{cases}
    1, & \text{if $x<t_1$}.\\
    i, & \text{if $t_{i-1} \leq x < t_i$}\text{.}\\
    k, & \text{if $t_{k-1} \leq x$}
  \end{cases}
\end{equation}

\noindent
The policy discretizes the continuous variable $C$ into $k$ intervals.
The discretization edges $t_\cdot$ are restricted to the midpoints between two sorted instances of $C$.
An integer representation of $M_C$ can be obtained by sorting the samples of $C$ in an increasing order, $\curly{c_1,c_2,\ldots,c_N}$, and if $t_i = (c_{s_{i}} + c_{s_{i}+1})/2$ for $i=1,2,\ldots,k$, then $M_C = \anglebrackets{t_1,t_2, \ldots, t_{k-1}} \equiv \brock{n_1,n_2,..n_k}$, where $n_1 = s_1$ and $n_i = s_{i} - s_{i-1}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discretization of a Single Continuous Variable}
\label{sec:single_var}

This section covers discretization of a single continuous variable $X$ in a Bayesian network where all other variables are discrete.
Let $n_p$ and $n_c$ respectively refer to the number of parents and number of children of $X$.
Each child $C_i$ of $X$ may possess other parents, referred to as spouses of $X$.
The set of spouses of $X$ is denoted $\boldsymbol{S_i}$.

Let $D$ be a dataset of $N$ samples from which the discretization will be learned, sorted in ascending order according to $X$.
Let $D_{\boldsymbol{Y}}$ will refer to the data instances associated with variables $\boldsymbol{Y}$, thus $D_X = \{ x_1,x_2,x_3,\ldots,x_N \}$.
In order to facilitate understanding, we temporarily assume all values in $D_X$ are unique, that is, $x_1 < x_2 < \ldots < x_N$.
It follows that a discretization policy $M$ on $X$ can be written as $M_X = \brock{n_1,n_2,\ldots,n_k}$, where $k$, $n_1$, $n_2$, $\ldots,n_k$ are positive integers satisfying $N = \sum_{i=1}^k n_i$.
An optimal discretization policy maximizes $P(M)\cdot P(D\mid M)$ for some prior $P(M)$ and likelihood $P(D\mid M)$.

%Furthermore, since there might have repeated values for $D_x$, we assume there are $N'$ unique values of $D_x$ and $N' \leq N$. Note that the allowable discretization edges happens between two consective values of non-repeated value of $D_x$. For example, if $D_X = \{ 1.0,1.0,2.0\}$, then the only possible discretization edge is on $1.5$.


\subsection{Priors and Objective Function}

The following four principles for the optimal discretization policy, modivated by MODL, enable the formulation of $P(M)$ and $P(D \mid M)$:
\begin{enumerate}
\item A discretization edge located at $(x_i + x_{i+1})/2$ has probability
\begin{equation}
1 - {\exp(- L \cdot {{x_{i+1} - x_i}\over{x_N - x_1}})},
\end{equation}
where $L$ is the largest cardinality number of discrete variables in $X$'s Markov blanket. \tim{Where does this come from? Is there an intuitive explanation?}
\item For a given interval of $M$, every distribution of $\Pi_X$ is equiprobable.
\item For each pair of $(C_i,\boldsymbol{S_i})$ and a given interval of $M$, every distribution of $C_i$ with a value of $\boldsymbol{S_i}$ is equiprobable.
\item The distributions of each $C_i$ and $\Pi_X$ in each interval of $M$ with each value of $\boldsymbol{S_i}$ are independent from each other.
\end{enumerate}

From the first principle one obtains
\begin{equation}
P(M) = \prod_{i=1}^k \curly{ \brock{1 - {\exp(- L \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}} \cdot \exp\paren{L \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}}}},
\end{equation}

\noindent
where $s_i = \sum_{j=1}^k n_j$ and $s_k = N$, $s_0 = 0$.
The Bayesian network graph structure causes the likelihood term $P(D \mid M)$ to factorizes according to $X$'s Markov blanket:

\begin{equation}
P\paren{D \mid M} \propto P\paren{D_{\Pi_x} \mid M} \cdot \prod_{i = 1}^{n_c} P\paren{D_{C_i} \mid M, D_{\boldsymbol{S_i}}}\text{.}
\end{equation}

For example, in Figure 1., the corresponding $P(D \mid M)$ is factorized according to
\begin{equation}
P\paren{D_{ P_1,P_2,P_3 } \mid M} \cdot P\paren{ D_{ C_1 } \mid M,D_{\boldsymbol{S_1}}} \cdot P\paren{D_{C_2} \mid M,D_{ S_2  }}\text{.}
\end{equation}

\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph1}
    \end{tabular}
  \caption{Factorization of $P(D \mid M)$}
\end{figure}


The concept behind the factorization also the motivation behind forward sampling in a Bayesian network.
The parents of $X$ are independent of the children given $X$.
The parents are not necessarily individually independent, and thus the parental term $P(D_{\Pi_x} \mid M)$ cannot be factored further.
The children of $X$ are similarly independent given $X$ and its spouses $\boldsymbol{S_i}$, leading to their factored product $\prod_{i = 1}^{n_c} P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$.
Each component in the decomposition be evaluated based on a discretization policy $M = [n_1,n_2,\ldots,n_k]$ and dataset $D$.

\subsubsection{Evaluation of $P(D_{\Pi_x} \mid M)$}
Let $J_P = \prod_{i=1}^{n_p} \| P_i \|$. It follows that

\begin{equation}
\label{eq:likelihood_one}
P(D_{\Pi_X} \mid M) = \prod_{i=1}^k  {{1}\over{{n_i + J_P - 1}\choose{J_P -1}}}
{{1}\over{ {{{n}_i}!}\over{ {n^{(p)}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_P} !}}  }}\text{,}
\end{equation}

\noindent
where $n^{(p)}_{i,j}$ is the number of instances in the $i$th discretized interval with the $j$th value of $\Pi_X$.
Note that $n_i = \sum_{j=1}^{\| \Pi_x \|} n^{(p)}_{i,j}$.
The two factors on the right hand side comes from the second prior: all distributions of values of $\Pi_X$ in a given interval are equiprobable. According to the fourth prior, the distribution in each interval is independent, so the two factors are multiplied together.

\subsubsection{Evaluation of $P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$}
For each pair $(C_j, \boldsymbol{S_j})$, let $\|C_j \| = J_j$ and $\| \boldsymbol{S_j} \| = L_j = \prod_{v \in \boldsymbol{S_j}} \| v \|$. It follows that

\begin{equation}
\label{eq:likelihood_two}
P(D_{C_j}  \mid M, D_{S_j}) =
\prod_{i=1}^{k} \prod_{l=1}^{L_j} {{1}\over{{n_{i,l} + J_j - 1}\choose{J_j-1}}}
{{1}\over{ {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}}  }}\text{,}
\end{equation}

\noindent
where $n^{(j)}_{i,m,l}$ is the number of instances in $i$th interval with $m$th value of $C_j$ and $l$th value of $\boldsymbol{S_j}$, $n_{i,l} = \sum_{m=1}^{J_j} n^{(j)}_{i,m,l}$, and $n_i = \sum_{l=1}^{L_j} n_{i,l}$.
The two factors on the right hand side come from the third prior: all distribution of values of $C_j$ in a given interval and with a given value of $S_j$ are equiprobable. According to the forth prior, these distributions are independent from each other, and one thus takes their product. If $S_j = \emptyset$, then Equation \ref{eq:likelihood_two} is equivalent to

\begin{equation}
\label{eq:likelihood_three}
P(D_{C_j}  \mid M) =
\prod_{i=1}^{k}  {{1}\over{{n_{i} + J_j - 1}\choose{J_j-1}}}
{{1}\over{ {{n_{i}}!}\over{ {n^{(j)}_{i,1,\emptyset} !} {n^{(j)}_{i,2,\emptyset} !} \cdots {n^{(j)}_{i,J_j,\emptyset} !}}  }}\text{,}
\end{equation}

\noindent
where $n^{(j)}_{i,m,\emptyset}$ is the number of instances in the $i$th interval with the $m$th value of $C_j$, and $\sum_{m=1}^{J_j} n^{(j)}_{i,m,\emptyset} = n_i$.

The objective function can be formulated given equations \ref{eq:p_M}, \ref{eq:p_D_given_M},\ref{eq:likelihood_one}, and \ref{eq:likelihood_three}.
The log-inverse of $P(M) \cdot P(D|M)$ is minimized for computational convenience:

\begin{equation}
\label{eq:opt_prob}
\begin{aligned}
& \sum_{i=1}^{k-1} - \log(1 - {\exp(- L \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}) +  \sum_{i=1}^{k} L \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}} +\\
&  \sum_{j=1}^{n_c} \sum_{i=1}^{k}  \sum_{l=1}^{L_j} \left[  \log{{n_{i,l} + J_j - 1}\choose{J_j-1}} + \log \left( { {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}} } \right) \right] + \\
& \sum_{i=1}^k \left[  \log {{n_{i} + J_P - 1}\choose{J_P-1}} + \log \left( { {{n_i}!}\over{ {n^{(p)}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_p} !}} } \right) \right]\text{.}
\end{aligned}
\end{equation}

All parameters and variables in the objective function are explained in previous subsections.

\subsection{Algorithm}

This section describes the procedure used to minimize the objective function.
Note that the objective function is cumulative over intervals, thus, if a partition of $X$ into $k$ intervals with lengths $n_1,n_2,\ldots,n_k$ is an optimal discretization policy, then any subinterval is optimal for the corresponding subproblem.
It follows that dynamic programming can be used to solve the optimization problem exactly.

Every midpoint between two nonequal consecutive values in $D_X$ is a candidate discretization edge.
Let ${D'_X} = \brock{x'_1,x'_2,\ldots,x'_M}$ be the set of unique values of $D_X$ sorted in ascending order, where $M$ is the number unique values in $D_X$.
Recall that $D_X$ is also sorted.
Let $b = \brock{b_0,b_1,b_2,\ldots,b_M}$ be an increasing sequence of integers marking the repeated value intervals in $D_X$ such that $b_0 = 0$ and $x_{b_{i-1} + 1} = x_{b_{i-1} + 2} = \ldots = x_{b_i} = x'_i$.
By this definition, the allowable discretization positions are $d_i = \paren{x_{b_{i}} + x_{{b_i}+1}}/2$ for all $i = 1,2,\ldots,M-1$.

Precomutation reduces runtime.
Compute $h(u,v)$ for each interval $I_q$ starting from $x_{u}$ to $x_{v}$ for all $(u,v)$ satisfying $u \leq v$:

\begin{small}
\begin{equation}
\begin{aligned}
h(u,v) &=  \log {{n_{q} + J_P - 1}\choose{J_P-1}} + \log \left( { {{n_q}!}\over{ {n^{(p)}_{q,1} !} {n^{(p)}_{q,2} !} \cdots {n^{(p)}_{q,J_p} !}} } \right) \\
& + \sum_{j=1}^{n_c} \sum_{l=1}^{L_j} \left[  \log{{n_{q,l} + J_j - 1}\choose{J_j-1}} + \log \left( { {{n_{q,l}}!}\over{ {n^{(j)}_{q,1,l} !} {n^{(j)}_{q,2,l} !} \cdots {n^{(j)}_{q,J_j,l} !}} } \right) \right]
\end{aligned}
\end{equation}
\end{small}

The evaluation of $h(u,v)$ for all $u \leq v$ is summarized in Algorithm \ref{alg:h} in the appendix.
The calculation has a $O(n_c  {v'_\text{max}} \cdot N^2 + {v'_\text{max}}^{n_p} \cdot N^2)$ runtime, where $n_c$ and $n_p$ are the numbers of child and parent variables respectively, and $v'_\text{max}$ is the largest cardinality of variables that directly connect to $X$.

Now we are able to solve the optimization problem over Equation \ref{eq:opt_prob}.
The dynamic programming procedure is shown in Algorithm \ref{alg:disc_one}.
It takes two inputs: $D$, the joint samples over all variables sorted in ascending order according to $D_X$, and $G$, the network structure.
The runtime of Algorithm \ref{alg:disc_one} is also $O(n_c  {v'_\text{max}} \cdot N^2 + {v'_\text{max}}^{n_p} \cdot N^2)$, because the runtime of the dynamic programming procedure is less than the runtime for computing $h(u,v)$.
Algorithm \ref{alg:disc_one} is guaranteed to be optimal.
For faster methods with suboptimal results please refer to \citep{Boulle_2006}.

\begin{algorithm}
\caption{Discretization of one continuous variable in a Bayesian network}
\label{alg:disc_one}
\begin{algorithmic}[5]
\Function{Discretize}{$D$, $G$}
\State
\State $N \leftarrow$ the number of instances
\State $N' \leftarrow$ the number of unique values in $D_X$
\State $H \leftarrow$ an $N \times N$ matrix such that $H[u,v] = h(u,v)$ per Algorithm \ref{alg:h} in the appendix
\State $b \leftarrow$ the increasing sequence of $M$ integers as previously defined
\State $L \leftarrow$ the largest cardinality over all discrete variables in the Markov blanket of $X$
\State $S[u] \leftarrow$ the optimal objective value of subproblems with instances from $1$ to $u$
\State $M[u] \leftarrow$ the optimal discretization for subproblems with instances from $1$ to $u$
\State $W[u]  \leftarrow - \log\brock{1 - {\exp\paren{- L \cdot{ {{x_{b(u)+1} - x_{b(u)}}\over{x_N - x_1}}}}}}$ for $u = 1,2, \ldots,N'-1$ and $L(N') \leftarrow 0$
\State
\For {$v = 1$ to $N'$}
\If {$v = 1$}
\State $S[v] \leftarrow g \left(1,b[v] \right) + L[v]$
\State $M[v] \leftarrow \{ ({x_{b[v]} + x_{b[v]+1}}) / 2\}$
\Else
\State $s \leftarrow \infty$ and $boundary \leftarrow \infty$
\For {$u = 1$ to $v$}
\State $s' \leftarrow S[u] + g \left( b[u]+1,b[v] \right) +  {L \cdot {{x_{b[v]} - x_{b[u] + 1}}\over{x_N - x_1}}} + W[v]$
\If {$s' < s$}
\State $s \leftarrow s'$
\State $boundary \leftarrow ({x_{b[u]} + x_{b[u]+1}}) / 2$
\EndIf
\EndFor
\State $S[v] \leftarrow s$
\State $M[v] \leftarrow M[u] \cup \{ boundary\}$
\EndIf
\EndFor
 \State \Return $M$
\EndFunction
\end{algorithmic}
\end{algorithm}


\subsection{Approximation}

Algorithm \ref{alg:disc_one} has an exponential $\bigo\paren{\paren{v'_\text{max}}^{n_p} \cdot N^2}$ runtime which severely limits discretization in networks with a large number of discretization intervals or parent variables.
This section introduces an approximation to the objective function that significantly reduces the runtime and still preserves the quality of discretization.
The approximation replaces the dominator of the last factor in Equation \ref{eq:likelihood_one} with

\begin{equation}
{\frac{{n_i}!}{ {n^{(p)}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_P} !}}} \approx \prod_{r=1}^{n_p} { {{{n}_i}!}\over{ {n^{(p_r)}_{i,1} !} {n^{(p_r)}_{i,2} !} \cdots {n^{(p_r)}_{i,J_{p_r}} !}}}\text{,}
\end{equation}

\noindent
where $J_{p_r} = \| P_r\|$ and ${n^{(p_r)}_{i,j} !}$ is the number of instances in the $i$th interval with the $j$th value of $P_r$.
The approximated objective function is

\begin{small}
\begin{equation}
\begin{aligned}
\label{eq:opt_prob_approx}
& \sum_{i=1}^{k-1} - \log(1 - {\exp(- L \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}) +  \sum_{i=1}^{k} L \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}} +\\
&  \sum_{j=1}^{n_c} \sum_{i=1}^{k}  \sum_{l=1}^{L_j} \left[  \log{{n_{i,l} + J_j - 1}\choose{J_j-1}} + \log \left( { {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}} } \right) \right] + \\
& \sum_{i=1}^k \left[  \log {{n_{i} + J_P - 1}\choose{J_P-1}} + \sum_{q=1}^{n_p} \log \left( { {{{n}_i}!}\over{ {n^{(p_q)}_{i,1} !} {n^{(p_q)}_{i,2} !} \cdots {n^{(p_q)}_{i,J_{p_q}} !}}} \right) \right]\text{.}
\end{aligned}
\end{equation}
\end{small}

The approximation reduces the runtime of Algorithm \ref{alg:disc_one} to a polynomial, $\bigo\paren{ {v'_\text{max}} \cdot (n_c + n_p) \cdot N^2}$.
It will be shown in Section \ref{sec:experiments} that the approximation is more sensitive to the distribution over other variables and is biased towards slightly higher interval counts.
\tim{We need to have a more specific thing to say along the lines of When does it fail?}

With the approximated objective function, Equation \ref{eq:opt_prob_approx}, provides intuition into how child and parent variables contribute to the objective function.
For example, in the left graph of Figure \ref{fig:example_networks}, the corresponding square brackets in the approximated objective function are

\begin{small}
\begin{equation}
\begin{aligned}
\label{eq:example_approx}
 \sum_{i=1}^k & \left\lbrace   \left[ \log{{n_{i} + J_{C_1} - 1}\choose{J_{C_1}-1}} + \log \left(  {{{n_i}!} \over { {n^{(1)}_{i,1,\emptyset} !} \cdots {n^{(1)}_{i,J_{C_1},\emptyset} !}} }  \right)  +  \right. \right.\\
& \left.  \log{{n_{i} + J_{C_2} - 1}\choose{J_{C_2}-1}} + \log \left(  {{{n_i}!} \over { {n^{(2)}_{i,1,\emptyset} !} \cdots {n^{(2)}_{i,J_{C_1},\emptyset} !}} }  \right)  \right] + \\
&  \left. \left[  \log {{n_{i} + J_P - 1}\choose{J_P-1}} +  \log \left( { {{{n}_i}!}\over{ {n^{(p_1)}_{i,1} !}\cdots {n^{(p_1)}_{i,J_{p_1}} !}}} \right) +{ {{{n}_i}!}\over{ {n^{(p_2}_{i,1} !}\cdots {n^{(p_2)}_{i,J_{p_2}} !}}}  \right] \right\rbrace \text{.}
\end{aligned}
\end{equation}
\end{small}

In Equation~\ref{eq:example_approx}, each child carries two terms, as shown in the first set of square brackets, but the two parent variables only carry a total of three terms, as shown in the second set of square brackets.
In this case the child variables have greater effect than the parent variables even though the number of child and parent variables are the same.
However, if $C_2$ has an additional parent $S_2$, as shown in the right graph of Figure~\ref{fig:example_networks}, the importances of $C_2$ will be reduced, because the information from $C_2$ is now affected by $S_2$.
This argument shows that the proposed method, both before and after approximation, indeed incorporates graph structure when discretizing continuous variables.

\begin{figure}[ht]
  \centering
  \begin{tabular}{cc}
    \input{graph2_left}
    \end{tabular}
   \hspace{5em}
    \begin{tabular}{cc}
    \input{graph2_right}
  \end{tabular}
  \caption{Two example networks}
  \label{fig:example_networks}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Extension to Multiple Continuous Variables}
\label{sec:multi_var}

\subsection{Discretization of Multiple Continuous Variables}

The single-variable discretization method can be extended to Bayesian networks with multiple continuous variables by iteratively discretizing variables individually.
The discretization process for a single variable requires that all other variables be discrete.
The iterative approach thus requires a prediscretization policy from which to initialize the process.
This work uses prediscretization with equal-width intervals, defined by

\begin{equation}
M_X = \curly{X_\text{min}, X_\text{min} + \delta, X_\text{min} + 2\delta, \ldots, X_\text{max}}\text{,}
\end{equation}

\noindent
where $X_\text{min}$ and $X_\text{max}$ are the extrema values of $D_X$, $\delta = (X_\text{max} - X_\text{min})/k$, and $k$ is the desired number of intervals.
This work sets $k$ to the median value of the cardinalities of initially discrete variables in the network.
After prediscretization, the one-variable discretization methis is iteratively applied over each continuous variable in reverse topoligical order, from the leaves to the root.
Let one such series of discretizations be a cycle.
Reverse topological order has the advantage of using less prediscretized instantiations during the first cycle.
For example, in the right-hand graph of Figure \ref{fig:example_networks}, assume $S_2$ is the only discrete variable.
The discretization of $P_1$ involves both $P_2$ and $X$, whereas the discretization of $C_1$ only involves $X$.

The algorithm is terminated when the number of discretization intervals and their associated edges converge for all variables.
A maximum cycle count is enforced to prevent infinite iterations when convergence does not occur.
The algorithm typically converges within a few cycles when tested on real-world data.
In cases where it does not converge, ten cycles usually produce decent discretization results.

The pseudocode for the multi-variable discretization procedure is shown in Algorithm \ref{alg:disc_two}.
It requires four inputs: $D''$, the joint samples from all network variables; $G$, the network structure; $C$, the set of all continuous variables in a reverse topological order; and $u_{cycle}$, the upper bound of times of cycles.

\begin{algorithm}
  \label{alg:disc_two}
  \caption{Discretization of multiple continuous variables \todo{Fix label reference number}}
  \begin{algorithmic}[5]
  \Function{Discretize}{$D''$, $G$, $C$, $u_{cycle}$}
    \State
    \State $M[i] \leftarrow$ the discretization policy for the $i$th variable
    \State $n \leftarrow$ the number of variables in the Bayesian network
    \State $D^*_i \leftarrow M[i] (D_i)$, list of samples $D_i$ discretized according to $M[i]$
    \State $D^* \leftarrow $ the discretized data for all variables, where $D^*_i \leftarrow D''_i$ if $i \notin C$
    \State $k \leftarrow median\{ |v|, v\notin C\}$
    \State
    \For {$i = 1$ to $n$}
      \If {$i \in C$}
        \State $M[i] \leftarrow$  equal-width discretization with $k$ intervals
        \State $D^*_i \leftarrow  M[i] (D''_i)$
      \EndIf
    \EndFor
    \State
    \State $cycle \leftarrow 0$
    \While {$M$ is not converged  \textbf{and} $cycle \leq u_{cycle}$}
      \State {$cycle  \leftarrow cycle  + 1$}
      \For {$j = 1$ to $|C|$}
        \State $D^*_{\backslash C(j)} \leftarrow D^*$ without $D^*_{C(j)}$.
        \State {$M[C(j)] \leftarrow $ DISCRETIZE($D_{C(j)}$,$D^*_{ \backslash C(j)}$,graph)}
        \State {$D^*_{C(j)}  \leftarrow$ $M[C(j)](D''_{C(j)})$}
      \EndFor
    \EndWhile
    \State \Return $M$
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Combining Discretization with Structure Learning}

In many situations the network structure is not known in advance and must be learned from data.
Traditional Bayesian structure learning algorithms require discretized data, whereas the proposed discretization algorithm requires a network structure.
This section combines the proposed discretization method with the K2 structure learning algorithm \citep{K2} in an interative fassion to simultaneously perform Bayesian structure learning and discretization of continuous variables.

The proposed algorithm alternates between K2 structure learning and discretization.
K2 is run on the discretized dataset corresponding to prediscretizations for all continuous variables.
The affected continuous variables are rediscretized every time an edge is added by K2.
The resulting discretization policies are used to update the discretized dataset, and the next step of the K2 algorithm is executed.
This cycle is repeated until the K2 algorithm reaches a local maximum.

This procedure is given in Algorithm \ref{alg:structure_learn}.
It takes five inputs: $D'$, the joint samples from all network variables; $C$, the set of all continuous variables; $order$, the permutation of variable for $K2$; $u_{parent}$, the upper bound on the number of parents per node for $K2$; and $u_{cycle}$, the upper bound on the cycle count.
It is common practice to run K2 multiple times with different permutations of the variables and to then choose the structure with the highest score.
This work runs Algorithm \ref{alg:structure_learn} multiple times, each with a different order, and picks the discretized Bayesian network with the highest score.

\begin{algorithm}
  \label{alg:structure_learn}
  \caption{ Learning a discrete-valued Bayesian network}
  \begin{algorithmic}[5]
  \Function{Learn\_DBN}{$D''$, $C$, $order$, $u_{parent}$, $C$, $u_{cycle}$}
    \State $n \leftarrow$ the number of variables in the Bayesian network
    \State $k \leftarrow median\{ \|v\|, v\notin C\}$
    \State $M[i] \leftarrow$ the discretization policy for the $i$th variable
    \State $D^*_i \leftarrow M[i] (D_i)$, list of samples $D_i$ discretized according to $M[i]$
    \State $D^* \leftarrow $ the discretized data for all variables, where $D^*_i \leftarrow D''_i$ if $i \notin C$
    \State $G \leftarrow$ the initial edgeless graph structure
    \For {$i = 1$ to $n$}
      \If {$i \in C$}
        \State $M[i] \leftarrow$  equal-width discretization with $k$ intervals
        \State $D^*_i \leftarrow  M[i] (D''_i)$
      \EndIf
    \EndFor
    \For {$i =1$ to $n$}
      \State $P_{old} \leftarrow f(X^*_i,\Pi_{X^*_i})$: Equation \ref{eq:f_x_p}
      \State OKToProceed $\leftarrow$ \textbf{true}
      \While {OKToProceed \textbf{and} $\|\Pi_{X^*_i}\| < u_{parent}$}
        \State $Y \leftarrow$ an element from the set $order[1:i] \backslash \Pi_X$
        \State $P_{new} \leftarrow f(X^*_i,\Pi_{X^*_i} \cup Y)$
        \If {$P_{new} > P_{old}$}
          \State $P_{old} \leftarrow P_{new}$
          \State $\Pi_{X_i} \leftarrow \Pi_{X_i} \cup Y $
          \State $M \leftarrow$ {DISCRETIZE}({$D''$, $G$, $C$, $u_{cycle}$}): Algorithm \ref{alg:disc_two}
          \State $D* = M(D'')$
        \Else
          \State OKToProceed $\leftarrow$ \textbf{false}
        \EndIf
      \EndWhile
    \EndFor
    \State \Return $G$, $M$
  \EndFunction
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments}
\label{sec:experiments}

This section describes experiments conducted to evaluate the proposed methods.
All experiments were run on datasets from the publically available Irvine machine learning repository \citep{Lichman:2013}.
Variables are labelled alphabetically in the order given on the dataset information webpage.
Subscripts inducate the number of discretized intervals.
Shaded nodes are originally discrete and unshaded nodes are originally continuous.

For each dataset, the experiment consists of two parts.
In the first part, the Bayesian network structure is known in advance, which is obtained by equal-width prediscretization and the K2 algorithm.
In the second part, the Bayesian netowrk structure is not provided in advance, and it is learned along with the discretization process.
\tim{We may not want to state this up front so we can modify what we show for each dataset.}

The discretizations are compared using the mean cross validated log-likelihood of the data set $D$ given the resulting graph structure $G$ and discretization policy set $\discset$.
The log-likelihood contains two components,

\begin{equation}
\ln p(D\mid G, \discset) = \ln P(D^*\mid G) + \ln p(D\mid \discset, D^*)\text{,}
\end{equation}

\noindent
where $D$ is the original dataset and $D^*$ is the dataset discretized according to $\discset$.
The log-likelihood of the discretized dataset is the Bayesian score evaluated with a uniform prior~\citep{neapolitan2004learning}:

\begin{equation}
  \ln P(D^*\mid G) = \sum_{i=1}^n \sum_{j=1}^{q_i} \ln\paren{
    \frac{
      \Gamma\paren{\alpha_{ij0}}
    }{
      \Gamma\paren{\alpha_{ij0} + m_{ij0}}
    }
  } + \sum_{k=1}^{r_i} \ln\paren{
    \frac{
      \Gamma\paren{\alpha_{ijk} + m_{ijk}}
    }{
      \Gamma\paren{\alpha_{ijk}}
    }
  }\text{.}
\end{equation}

\tim{We need to make sure everything is defined.}

The log-likelihood of the original dataset given the discrete dataset is

\begin{equation}
  \ln p(D\mid \discset, D^*) = \sum_{i=1}^n \sum_{j=1}^{q_i} \sum_{k=1}^{r_i} m_{ijk} \ln\paren{
    \frac{
      1
    }{
      \discset^{(ij)}_{k+1} - \discset^{(ij)}_{k}
    }
  }\text{.}
\end{equation}

\subsection{Auto MPG Dataset}

In this subsection, two experiments are conducted on the Auto MPG dataset from the Irvine repository \citep{Lichman:2013}.
The dataset has \num{392} instances after deleting the six instances with missing data, and eight variables.
Three variables are discrete: $B$, $G$, and $H$ with cardinality 5, 13, and 3 respectively.
Two expiriments are conducted, one with a given network structure and one in which the structure is learned.

\subsubsection{Structure is Given}

The proposed discretization method and the MDL discretization method are tested on Auto MPG data given the network network in Fig. \ref{Auto_graph_1}.
The structure was obtained by prediscretizing each continuous variable into five uniform-width intervals, where five is the median cardinality of the discrete variables, and then taking the most frequent structure from a thousand runs of K2.

\begin{figure}[ht]
  \centering
  \begin{tabular}{cc}
    \input{graph_autocar_1}
  \end{tabular}
  \caption{The Bayesian network obtained with K2 on the prediscretized Auto MPG dataset}
  \label{Auto_graph_1}
\end{figure}

Table \ref{Auto_MPG_disc_table_1} shows the numbers of intervals after discretization, the positions of discretization edges, and log-likelihood of 10-fold cross validation. For the Bayesian network in Fig. \ref{Auto_graph_1}, the approximation only reduces runtime of proposed method and has no influence on discretization result. MDL principle discretization works not well, since it discretizes all variables with only one interval. For a Bayesian network on thie Auto MPG data set that MDL principle discretization has non-trivial result, please reference to Appendix.

\begin{table}[h]
  \centering
  \input{table_autoMPG_1.tex}
  \caption{Discretization result of Auto MPG dataset based on the graph in Fig. \ref{Auto_graph_1}. The discretization policy for the heuristic matches that for the optimal Bayesian approach. \todo{Need to explain why MDL fails}}
  \label{Auto_MPG_disc_table_1}
\end{table}

Figure \ref{auto_exp1_distr_1_3} compares the discretization result on continuous variables $A$ and $C$ with the raw data of Auto MPG data set. The color of discretized area shows the probability of a sample being in the discretized area. The black dots in Figure \ref{auto_exp1_distr_1_3} demonstrate the distribution of the raw data. As shown in the figure, the discretization edges and the resulting marginalized probability match the raw data very well.

\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph_auto_exp1_distr_1_3}
    \end{tabular}
  \caption{Comparison of the raw data and discretization result on variable $A$ and $C$}
  \label{auto_exp1_distr_1_3}
\end{figure}

\subsubsection{Structure is Learned}

If the network structure is not known in advance, it should be learned along with the discretization process. Figure \ref{Auto_graph_2} and Table \ref{Auto_MPG_disc_table_2} show a learned discrete-valued Bayesian network and the corresponding discretization edges of each continuous variable. This result is obtained by running Algorithm \ref{Learn_DBN} fifty times and choosing the one with the highest K2 score.
\newline

 {\centering
\begin{minipage}{0.50\textwidth}
  \centering
  \scalebox{0.7}{
  \input{graph_autocar_2}}
  \captionof{figure}{The learned discrete-\newline valued Bayesian network}
  \label{Auto_graph_2}
\end{minipage}
\begin{minipage}{0.50\textwidth}
  \raggedleft
  \input{table_autoMPG_2.tex}
  \captionof{table}{The discretization edges of variables in Fig \ref{Auto_graph_2}}
  \label{Auto_MPG_disc_table_2}
\end{minipage}
}

Figure \ref{auto_exp2_distr_1_3} compares the result of Figure \ref{Auto_graph_2} and Table \ref{Auto_MPG_disc_table_2} with the raw data on variables $A$ and $C$. Again, the black dots are raw data points. Although the numbers of discretization edges of $A$ and $C$ shown in Table \ref{Auto_MPG_disc_table_2} are less than Table \ref{Auto_MPG_disc_table_1}, they still have a good capture of raw data distribution.

\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph_auto_exp2_distr_1_3}
    \end{tabular}
  \caption{Comparison of the raw data and discretization result on variable $A$ and $C$ according to Figure \ref{Auto_graph_2} and Table \ref{Auto_MPG_disc_table_2}}
  \label{auto_exp2_distr_1_3}
\end{figure}


\subsection{Dataset 2: Wine}
\label{subsec:wine}

In this subsection, two experiments are conducted on the Wine dataset from the Irvine repository \citep{Lichman:2013}. This dataset has 178 instances and 14 variables. Only variable $A$ is discrete-valued with cardinality number 3. Again, in the first experiment, the network structure is given. In the second experiment, the network structure is not provided.

\subsubsection{Experiment 1 on Wine dataset}
\label{subsubsec:wine_exp2}

Figure \ref{Wine_graph_1} is obtained by equal-width discretizing each continuous variable into 3 intervals and running K2 1000 times. Table \ref{Wine_disc_table_1} shows a comparison between the proposed method and the MDL principle discretization method. The proposed method is still better than MDL principle discretization in terms of likelihood, although the latter returns non-trivial result in this experiment. Furthermore, the proposed method with the approximation has more intervals after discretization, thus it has a slightly better result. However, as shown in next dataset, the approximation might cut continuous variables into too many intervals. Therefore, the proposed method without the approximation should be still considered a better approach.


\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph_wine_1}
    \end{tabular}
  \caption{K2 structure learning with prediscretization on Wine dataset}
  \label{Wine_graph_1}
\end{figure}

\begin{table}
\centering
\scalebox{1.0}{
\input{table_wine_1.tex}
}
\caption{Discretization result of Wine dataset based on the graph Fig. \ref{Wine_graph_1}}
\label{Wine_disc_table_1}
\end{table}



\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph_wine_2}
    \end{tabular}
  \caption{K2 structure learning with the proposed discretization method on Wine dataset}
  \label{Wine_graph_2}
\end{figure}


\subsection{Data 3: Housing}
\label{subsec:housing}

\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph_housing_1}
    \end{tabular}
  \caption{K2 structure learning with prediscretization on Housing dataset}
  \label{Housing_graph_1}
\end{figure}



\begin{table}
\centering
\scalebox{1.0}{
\input{table_housing_1.tex}
}
\caption{Discretization result of Housing dataset based on the graph Fig. \ref{Housing_graph_1}}
\label{Housing_disc_table_1}
\end{table}

\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph_housing_2}
    \end{tabular}
  \caption{K2 structure learning with the proposed discretization method on Housing dataset}
  \label{Housing_graph_2}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
%\begin{thebibliography}{}
\bibliographystyle{spbasic}
\bibliography{my_bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Appendices}

\begin{algorithm}
  \caption{ Calculation of $h(u,v)$ for all $u \leq v$}
  \label{alg:h}
  \begin{algorithmic}[1]
  \State Initialize $H$ as an $N \times N$ matrix such that all elements are 0.
  \State $count_p$ is an $N \times N \times \|\Pi_X\|$ matrix such that $count_p [u,v,w]$ is the number of instances from $x_u$ to $x_v$ with $w$th value of $\Pi_X$. This matrix can be calculated in $O(\|\Pi_X\| \cdot N^2)$
  \For {$u = 1$ to $N$}
    \For {$v = u$ to $N$}
      \State $H(u,v) \leftarrow H(u,v) + \log((v-u + J_p)!) - \log((J_p -1)!)$
      \For {$w = 1$ to $\|\Pi_X\|$}
        \State $H(u,v) \leftarrow H(u,v) - \log( count_p(u,v,w)!)$
      \EndFor
    \EndFor
  \EndFor
  \For {$j = 1$ to $n_c$}
    \State \todo{XXX}
  \EndFor
  \end{algorithmic}
\end{algorithm}

\end{document}
% end of file template.tex

