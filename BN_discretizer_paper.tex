%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{amsmath}
\usepackage{bm}
\usepackage{graphicx} % Allows including images
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[round]{natbib}
\setcitestyle{aysep={ }} %Author-Year SEParator
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%
\begin{document}

\title{Learning Discrete-valued Bayesian Networks from Mixed Data%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{First Author         \and
        Second Author         \and
        Third Author%etc.
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{F. Author \at
              first address \\
              Tel.: +123-45-678910\\
              Fax: +123-45-678910\\
              \email{fauthor@example.com}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           S. Author \at
              second address
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
Insert your abstract here. Include keywords, PACS and mathematical
subject classification numbers as needed.
\keywords{Discretization \and Bayesian Network \and Continuous Variable}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\section{Introduction}
\label{intro}
Bayesian networks \citep{Pearl_1988, PGM_2009}  are an increasingly popular method for modeling uncertainty and causality in science and engineering. They provide an efficient factorization of the joint probability distribution over a set of random variables. Bayesian networks first emerged from artificial intelligence research and have been applied to a wide variety of problems, ranging from decision-making systems \citep{DMU_2015} to medical diagnoses. In most cases, we assume that all random variables in Bayesian networks are discrete, since many algorithms on Bayesian networks are unable to deal with continuous variables efficiently. However, the assumption that all variables are discrete is often too restrictive. For example, in the decision-making system of autonomous cars, it is imperative to deal with continuous variables such as position and velocity.

There are two methods around this assumption. The first one is to model conditional probability density of each continuous variable by specific families of parametric distributions, then redesign algorithms on Bayesian networks based on these parameters. One successful example is belief propagation in Gaussian graphical models \citep{Weiss_2011}. Nevertheless, for other shapes of particles \citep{Ihler_2009} or non-linear functions, these redesigned algorithms are computationally expensive and do not perform well.

The second method around continuous variables is to discretize them. Discretization that learns from data has been developed well and discussed in the fields of machine learning and statistics for many years \citep{Dougherty_1995, Kerber_1992, Holte_1993, Fayyad_1993} . Most of these discretization methods are designed for classification problems. They search the best discretization policy of a continuous attribute by considering its interation with the class variable of interest. However, these discretization methods do not apply to continuous variables in Bayesian networks. In Bayesian networks, interations and dependencies between variables are determined by graph structure. Therefore, if a method discretizes continuous variables according to graph structure, instead of assigning one variable as a class variable, then it would be more appropriate. There is some reseach on discretizing continuous variables in naive Bayesian networks and tree augmented networks \citep{Fried_naive}, but only a few discretization methods on general Bayesian netowrk have been proposed \citep{Friedman_1996, Kozlov_1997, Monti_1998, Steck_2007}. 

The discretization technique proposed by \citet{Friedman_1996} is the most well-known one among these few methods. It is based on minimum description length principle (MDL): optimal discretization policy minimizes the description length of Bayesian network and data information. If there is only one continuous variable in Bayesian network and other variables are discrete, this MDL discretization method takes running time $O(N^3 + n_c {v_{max}}^{(n_c^p)_{max}} \cdot N^2 + {v_{max}}^{n_p} \cdot N^2)$, where $N$ is the number of data instances for learning the discretization, $n_p$ and $n_c$ are the numbers of parent and children variables for the continuous variable, $v_{max}$ is the largest cardinality number over all variables in Markov blanket, and  ${(n_c^p)_{max}}$ is the largest number of parent variables of the continuous variable's children. If there are multiple continuous variables in the network, the method iterates over all continuous variables until convergence. In our test on real world data, the iterations converge in a few cycles. However, the number of intervals after discretization is too small.

In this paper, we propose a new discretization method for continuous variables in Bayesian networks by learning from mixed data. This method is a generalized version of  \citet{Boulle_2006} and \citet{Lustgarten_2011}, which are both discretization methods of a continuous attribute with one class variable. We begin our method with the assumption that only one variable in a given Bayesian network is continuous and other variables are discrete. Furthermore we assume that the network structure is known in advance. Under this situation, we look for the most probable discretization policy $M$ given the data $D$ on other discrete variables. That is to say, the desired policy is $\textrm{arg}_M P(M \mid D)$. With Bayes' rule, $P(M \mid D) $ can be rewritten as $P(M) \cdot P(D \mid M) / P(D)$ , which is proportional to $P(M)\cdot P(D \mid M)$. Usually, $P(D \mid M)$ increases as the number of discretized intervals increases, since more intervals can provide more accuracy. $P(M)$, on the other hand, is designed to decrease as the number of intervals rises. As a result, we can automatically determine the number of intervals after discretization by maximizing  $P(M)\cdot P(D \mid M)$. In addition, the $P(D \mid M)$ can be factorized according to Bayesian network structure. With the proposed priors, we are able to restrict the number of discretized intervals so that it will not exceed the largest cardinality number of variables in the Markov blanket by too much. This is important, since for most algorithms on Bayesian networks, their running times exponentially depend on the cardinality of variables. Another advantage of our method is the running time for learning. If there is only one continuous variable, the running time is $O(n_c  {v_{max}} \cdot N^2 + {v_{max}}^{n_p} \cdot N^2)$, which is significiantly shorter than the running time of MDL principle discretization \citep{Friedman_1996}. With the approximation proposed in this paper, we can further reduce running time to $O({v_{max}}(n_p+n_c)N^2)$.

For a Bayesian network with multiple continuous variables, we apply the discretization method discussed above iteratively. In the beginning, we prediscretize each continuous variable by equal-width method. The number of intervals for equal-width discretization is equal to largest cardinality of discrete variables. Then we iterate the one-variable discretization on each continuous variable in the following order: from the variable with highest topological order (leaves) to the variable with lowest topological order (root). Each time we finish a discretization procedure on one variable, we store the discretization result for later iterations. Experiments on real data show that with the same iteration order, our discretization method provides better discretization results than MDL principle method in terms of likelihood. The MDL principle method is easily stuck at local minima and also discretizes variables into too few intervals.

Finally, we can combine the our new discretization method with K2 structure learning alorithm \citep{K2}. We first prediscretize all continuous variables before K2 learning, since the K2 algorithm requires all variables to be discrete. Each time an edge is added in the K2 algorithm procedure, we rediscretize the relevant variables in the learned Bayesian network and store the result for next K2 algorithm iteration. By this principle, we are able to learn a discrete-valued Bayesian network from mixed data.

The rest of the paper is organized as follows: related works, including MDL principle discretization \citep{Friedman_1996} and MODL discretization by \citet{Boulle_2006}, are summarized in Section 2. We prepare the preliminaries and notations in Section 3. In Section 4, we introduce the new discretization method for the case that only one variable is continuous, including the derivation of objective function and the algorithms. Section 5 is a discussion about multiple continuous variables in a Bayesian network and how to discretize them. The combination of our proposed discretization and K2 structure learning is also introduced. Finally, in Section 6, we apply the proposed discretization method to real-world data and show the result.

\section{Related Work}
\label{relat_work}
In this section we review two related works: MDL principle discretization \citep{Friedman_1996} and MODL discretization \citep{Boulle_2006}. The former is the most famous discretization method for continuous variables in Bayesian networks, and we will compare it with our proposed method in Section 6. The latter is a discretization method for one continuous attribute according to a target class. Our proposed method is a generalization of this method. Note that MODL discretization is a Bayesian approach. The asymptotical equivalence between MDL approach and Bayesian approach has been examined in \citep{VL_2000}.
\subsection{MDL Principle Discretization}
\label{MDL}
The MDL principle was first proposed by \cite{MDL_1978}. It provides a way to compress data, that is to say, describe data with fewer number of symbols than the number of symbols needed to describe the data literally \citep{Grunwald_2009}. MDL chooses a model that trades off goodness-of-fit for the complexity of model. Therefore it has an advantage that automatically avoids overfitting. In the case of Bayesian networks, \citep{Friedman_1996} applied the MDL concept to determine the number of intervals of each continuous variable after discretization and also the positions of discretization boundaries. Here is the mechanism: MDL principle discretization selects a discretization policy that minimizes sum of description lengths of discretized Bayesian network and the necessary information that recovers original data from discretized data. If there is only one continuous variable and other variables are discrete, the objective function is  
\begin{equation}
\begin{aligned}
&{1 \over 2} log(N) \{  \lVert \Pi_{X_i} \rVert (\lVert X^*_i \rVert - 1) +
 {\sum_{j,X_i \in \Pi_{X_i}}} \lVert \Pi_{X^*_j} \rVert (\lVert X_j \rVert - 1) \} + \\
& log(\lVert {X^*_i} \rVert) + log{{N_{i}-1}\choose{\lVert {X^*_i} \rVert -1}}  -N \cdot [I(X^*_i,\Pi_{X_i}) + {\sum_{j,X_i \in \Pi_{X_i}}} I(X_j, \Pi_{X^*_j})],
\end{aligned}
\end{equation}
where function $I(\boldsymbol{A},\boldsymbol{B}) = \sum_{\boldsymbol{a},\boldsymbol{b}} \hat{P}_D (\boldsymbol{a},\boldsymbol{b}) log {{\hat{P}_D (\boldsymbol{a},\boldsymbol{b})}\over{\hat{P}_D (\boldsymbol{a}),\hat{P}_D (\boldsymbol{b})}}$ is the mutual information between two sets of variables $\boldsymbol{A}$ and $\boldsymbol{B}$, $||\boldsymbol{X}||$ means the cardinality of variable $\boldsymbol{X}$ and $X^*_i$ is the discretized version of continuous variable $X_i$. The optimal discretization policy can be found by dynamical programming. If there are multiple continuous variables in Bayesian network, we apply the algorithm on one variable at a time and iterate over all continuous variables. While iterating, only one variable is treated as continuous and other continuous variables are discretized based on initial prediscretization or the discretization result of previous iteration.

For the above discretization processes, the network structure is known in advance. If the network structure is not given, we can alternate between structure learning and discretization learning. We start with some discretization, and learn a network structure given this discretization. Then, we rediscretize based on the learned network. This cycle continues until no improvement in objective function is made.
\subsection{MODL Discretization}
\label{MODL}
MODL discretization \cite{Boulle_2006} is a Bayesian-approach discretization. It discretizes a continuous feature according to a class variable. The best discretization model is found by maximizing the probability $P(\textit{Model} \mid \textit{Data})$ of the model given the data. Using the Bayesian rule and since $P(\textit{Data})$ is a constant while varying the discretization model, this is equivalent to maximize:
\begin{align}
P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model}).
\end{align}
Once the prior distribution of the discretization model is fixed, each term in Eq (3) can be evaluated. Usually, $P(\textit{Data} \mid \textit{Model})$ increases as the number of intervals of discretization model increases, since more intervals means that the model contains more information and thus it is easier to reproduce the original data. On the other hand, $P(\textit{Model})$ decreases as the number of intervals increases. Thus, maximizing $P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model})$ provides a trade-off to determine number of intervals after discretization. 

The MODL method adapts dynamical programming to find the optimal discretization model, and it takes running time $O(N^3 + ||\text{Class}|| \cdot N^2)$, where $N$ is number of data instances. \cite{Lustgarten_2011} provide a different prior to evaluate $P(\text{Model})$ term. This prior could include the assumption of uniform prior probabilities over discretization in MODL as a special case. Additionally, it reduces runing time to $O(||\text{Class}|| \cdot N^2)$.


\section{Preliminaries}
\label{Prelim_Notation}
In this section we provide a brief review of Bayesian networks, including the factorization of joint probability distribution, sampling from a given network, and structure learning. These concepts will be used in later sections.

\subsection{Bayesian Network and Structure Learning}
\label{BN_basic}
A Bayesian network $B$ is defined by a pair $(G,\Theta)$, where $G = (X,E)$ is a directed acyclic graph whose nodes correspond to a set of random variable $X = \{  X_1, X_2, \cdots, X_n \}$, and whose edges $E$ represents probabilistic dependencies among nodes. The graph structure $G$ encodes the Markov property: each node $X_i$ is independent of its non-descendants given its parents in $G$. The second component of $B$, namely $\Theta$, contains a set of parameters that qualify the network. Elements of $\Theta$ take the form $\theta_{x_i \mid \Pi_{x_i}} = P(x_i \mid \Pi_{x_i})$ for each possible value $x_i$ of $X_i$, and $\Pi_{x_i}$ of $\Pi_{X_i}$ (the set of parents of $X_i$ in $G$). Applying Markov property, we can represent the multivariate joint distribution over $X$ as
\begin{equation}
P_B (X_1 , \cdots, X_n) = \prod_{i=1}^{n} P_B (X_i \mid \Pi_{X_i}) = \prod_{i=1}^{n} \theta_{x_i \mid \Pi_{x_i}}
\end{equation}

For a given Bayesian network, we can generate its data instances by forward sampling, i.e., sampling variables one by one in a topological order \citep[see][chap.~22]{algo_2009}. Given an instance of $X_i$'s parent set, $\Pi_{X_i}$, values of $X_i$ can be sampled according to the conditional probability table $P(X_i \mid \Pi_{X_i})$. Furthermore, this parent-child sampling order can be reversed if we know the marginal probability of child variable $P(X_i)$. By Bayes rule,
\begin{equation}
P(X_i \mid \Pi_{X_i}) \cdot \prod_{j = 1}^{ Pa( X_i)} P( \{ \Pi_{X_i} \}_j) = P(X_i) \cdot P(\Pi_{X_i} \mid X_i),
\end{equation}
where $Pa( X_i)$ is the number of parents of $X_i$, and $\{ \Pi_{X_i} \}_j$ is the $j$th parent of $X_i$. We can first sample $X_i$ by $P(X_i)$, then sample all the parent variables simultaneously by $P(\Pi_{X_i} \mid X_i)$. That is to say, $X_i$ becomes the starting point for sampling.

If we don't know the structure of the Bayesian network in advance, then we need to learn it from data. Roughly speaking, there are three approaches to learn a Bayesian network structure from data \citep[see][chap.~18]{PGM_2009}: constraint-based structure learning, score-based structure learning, and Bayesian model averaging. Here we review K2 structure learning algorithm \citep{K2}, which is one of the most successful score-based structure learning methods. Similar to most structure learning algorithms, the K2 algorithm requires all variables to be discrete. The score of a learned network is defined as $\prod_i f(X_i, \Pi_{X_i})$, where
\begin{align}
f(X_i, \Pi_{X_i}) = \prod_{j=1}^{||\Pi_{X_i}||} {{(||X_i||-1)!}\over{(N_{ij} + ||X_i||-1)!}} \prod_{k=1}^{||X_i||} \alpha_{ijk}!.
\end{align}
$||X_i||$ is the cardinality of variable $X_i$. $||\Pi_{X_i}||$ is number of all possible instantiations of the parent variables of $X_i$, i.e., $|\Pi_{X_i}| = \prod_{Y \in \Pi_{X_i}} |Y|$. $\alpha_{ijk}$ is the number of instances in a data set that variable $X_i$ is instantiated with its $k$th value, and the parent of $X_i$ are instantiated with the $j$th value of $\Pi_{X_i}$. $N_{ij} = \sum_{k=1}^{|X_i|} \alpha_{ijk}$. 

K2 algorithm searches the network structure with the highest score, which can be interpreted as the most probable network with the given data. In addition, K2 requires a topological order of variables to be known before scoring can start. This constraint can prevent cycles from being introduced. The searching for high-score network is an iterative process. There is no way to find the optimal network directly, since there are $2^{O(n^2)}$ possible structures, where $n$ is number of variables. In order to compensate for this, we run K2 algorithm many times, and each time we start with a different order of variables. The network with the highest score in iterations is the desired one.

\subsection{Discretization Policy}
\label{Disc_p}
A Discretization Policy $M_C = < t_1,t_2, ..., t_{k-1} >$ on a continuous variable $C$ is a mapping from $\boldsymbol{R}$ to $\{1,2,3,...,k \}$ such that
\begin{equation}
  M_C (x)=\begin{cases}
    1, & \text{if $x<t_1$}.\\
    i, & \text{if $t_{i-1} \leq x < t_i$}.\\
    k, & \text{if $t_k \leq x$}
  \end{cases}
\end{equation}
That is to say, the policy discretizes the continuous variable $C$ into $k$ intervals. Furthermore, we assume that the discretization edge $t_i$ can only take values on middle points of two consective values of data of $C$. By this assumption, we can obtain an integer representation of $M_C$ as follows: 
we sort the data of continuous variable $C$ in an increasing order, $\{ c_1,c_2,...,c_N \}$, and if $t_i = (c_{s_{i}} + c_{s_{i}+1})/2$ for $i=1,2,...,k$, then $M_C = < t_1,t_2, ..., t_{k-1} > \equiv [n_1,n_2,..n_k]$, where $n_1 = s_1$ and $n_i = s_{i} - s_{i-1}$ for $i = 2,...,k$.\\

\section{Discretize One Continuous Variable}
\label{one-conti}
In this section, we consider the case that only one variable in a Bayesian network is continuous and the others are discrete. Before we formulate the objective function, we introduce some notations that will make the following calculation easier.
\subsection{Notations}
\label{Notation}
Assume the continuous variable is $X$. It has $n_p$ parent variables, $\Pi_X = \{ P_1, P_2, P_3,...,P_{n_p}\}$. It also has $n_c$ child variables $\{ C_1, C_2,...,C_{n_c}\}$. Each child variable $C_i$ of $X$ has other parent variables, which forms a set $\boldsymbol{S_i}$. Before we do the discretization, we sort the data instances by its attribute of $X$.

Let $D \cup D_X$ be a dataset of $N$ instances which we plan to learn discretization from. $D_X$ only contains the data of $X$. $D$ contains the data of all variables except $X$.  Assume $D \cup D_X$ has been sorted in the ascending order of $D_X$. In the following content, $D_{\boldsymbol{Y}}$ means the data instances of a set of variable $\boldsymbol{Y}$. Let $D_X = \{ x_1,x_2,x_3,...,x_N \}$. In order to make the discretization mechanism more understandable, we temporarily assume there is no repeated values in $D_X$, i.e., $x_1 < x_2 < ... < x_N$. We will remove this assumption later in the algorithm section. Therefore, a discretization policy $M$ on $X$ can be written as $M = [n_1,n_2,...,n_k]$, where $k$, $n_1$, $n_2$,..., and $n_k$ are positive integers satisfying $N = \sum_{i=1}^k n_i$.

%Furthermore, since there might have repeated values for $D_x$, we assume there are $N'$ unique values of $D_x$ and $N' \leq N$. Note that the allowable discretization edges happens between two consective values of non-repeated value of $D_x$. For example, if $D_X = \{ 1.0,1.0,2.0\}$, then the only possible discretization edge is on $1.5$. 


\subsection{Priors and Objective Function}
\label{obj}
We have the following four priors for the discretization model $M$ that enable us to evaluate $P(M)$ and $P(D \mid M)$:\\
\begin{enumerate}
\item For a discretization edge locating at $(x_i + x_{i+1})/2$ has probability
\begin{equation}
1 - {exp(- M \cdot {{x_{i+1} - x_i}\over{x_N - x_1}})},
\end{equation}
where $M$ is the largest cardinality number of discrete variables in $X$'s Markov blanket.
\item For a given interval of $M$, every distribution of $\Pi_X$ is equiprobable.
\item For each pair of $(C_i,\boldsymbol{S_i})$ and a given interval of $M$, every distribution of $C_i$ with a value of $\boldsymbol{S_i}$ is equiprobable.
\item The distributions of each $C_i$ and $\Pi_X$ in each interval of $M$ are independent from each other.
\end{enumerate} 

Owing to these priors, we are able to evaluate $P(M)$ and $P(D \mid M)$. For the former, we have
\begin{equation}
P(M) = \prod_{i=1}^k \{ [1 - {exp(- M \cdot {{x_{s_i+1} - c_{x_i}}\over{x_N - x_1}})}] \cdot exp(M \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}}) \},
\end{equation}
where $s_i = \sum_{j=1}^k n_j$ and $s_k = N$, $s_0 = 0$. Before evaluating $P(D \mid M)$, notice that
\begin{equation}
P(D \mid M) \propto P(D_{\Pi_x} \mid M) \cdot \prod_{i = 1}^{n_c} P(D_{C_i} \mid M, D_{\boldsymbol{S_i}}).
\end{equation}
The graph structure allows us to only consider the interations between $X$ and other variables in its Markov blanket and also make the factorization. For example, in Figure 1., the corresponding $P(D \mid M)$ is factorized as
\begin{equation}
P(D_{ P_1,P_2,P_3 } \mid M) \cdot P( D_{ C_1 } \mid M,D_{\boldsymbol{S_1}}) \cdot P(D_{C_2} \mid M,D_{ S_2  }).
\end{equation} 

% For one-column wide figures use
\begin{figure}
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[width=6cm]{graph1.png}
% figure caption is below the figure
\caption{Factorization of $P(D \mid M)$}
\label{fig:1}       % Give a unique label
\end{figure}

The concept behind the factorization is similar to sampling in a Bayesian network. Once we have the distribution of $X$ and sample $X$ for it, then we can further sample $\Pi_x$. Since the samples of variables in $\Pi_x$ are not independent, we can not further factorize $P(D_{\Pi_x} \mid M)$ into $\prod_i P(D_{P_i} \mid M)$. Similarly, once we have a set of samples of $X$ and $\boldsymbol{S_i}$, we can sample $C_i$. Since the sampling processes of child variables are independent from each other, we have the product $\prod_{i = 1}^{n_c} P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$.\\

For the following part, we evaluate $P(D_{\Pi_x} \mid M)$  and $P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$ based on discretization policy $M = [n_1,n_2,...,n_k]$ and dataset $D$.
\subsubsection{Evaluate $P(D_{\Pi_x} \mid M)$}
Assume that $J_P = \prod_{i=1}^{n_p} || P_i ||$. Then we have:
\begin{equation}
P(D_{\Pi_X} \mid M) = \prod_{i=1}^k  {{1}\over{{n_i + J_P - 1}\choose{J_P -1}}}
{{1}\over{ {{{n}_i}!}\over{ {n^{(p)}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_P} !}}  }},
\end{equation}
where $n^{(p)}_{i,j}$ is the number of instances in $i$th discretized interval with $j$th value of $\Pi_X$. Note that $n_i = \sum_{j=1}^{|| \Pi_x ||} n^{(p)}_{i,j}$. The two factors on RHS comes from the second prior: all distributions of values of $\Pi_X$ in a given interval are equiprobable. According to the forth prior, the distribution in each interval is independent, so we multiply all the two factors together.
\subsubsection{Evaluate $P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$}
Assume for each pair of $(C_j, \boldsymbol{S_j})$, we have $||C_j || = J_j$ and $|| \boldsymbol{S_j} || = L_j = \prod_{v \in \boldsymbol{S_j}} || v ||$. Therefore,
\begin{equation}
P(D_{C_j}  \mid M, D_{S_j}) =
\prod_{i=1}^{k} \prod_{l=1}^{L_j} {{1}\over{{n_{i,l} + J_j - 1}\choose{J_j-1}}}
{{1}\over{ {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}}  }},
\end{equation}
where $n^{(j)}_{i,m,l}$ is the number of instances in $i$th interval with $m$th value of $C_j$ and $l$th value of $\boldsymbol{S_j}$, $n_{i,l} = \sum_{m=1}^{J_j} n^{(j)}_{i,m,l}$, and $n_i = \sum_{l=1}^{L_j} n_{i,l}$. The two factors on RHS comes from the third prior: all distribution of values of $C_j$ in a given interval and with a given value of $S_j$ are equiprobable. According to the forth prior, these distributions are independent from each other, therefore we multiply all factors. If $S_j = \emptyset$, then Equation 13. is equivalent to
\begin{equation}
P(D_{C_j}  \mid M) =
\prod_{i=1}^{k}  {{1}\over{{n_{i} + J_j - 1}\choose{J_j-1}}}
{{1}\over{ {{n_{i}}!}\over{ {n^{(j)}_{i,1,\emptyset} !} {n^{(j)}_{i,2,\emptyset} !} \cdots {n^{(j)}_{i,J_j,\emptyset} !}}  }},
\end{equation}
where $n^{(j)}_{i,m,\emptyset}$ is the number of instances in $i$th interval with $m$th value of $C_j$, and $\sum_{m=1}^{J_j} n^{(j)}_{i,m,\emptyset} = n_i$. \\

With Equation 8,9,11,12, and 13, now we are able to write down the objective function. Instead of maximizing $P(M) \cdot P(D|M)$, we minimize its log-inverse for convenience. The objective function is
\begin{equation}
\begin{aligned}
& \sum_{i=1}^{k-1} - log(1 - {exp(- M \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}) +  \sum_{i=1}^{k} M \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}} +\\
&  \sum_{j=1}^{n_c} \sum_{i=1}^{k}  \sum_{l=1}^{L_j} \left[  log{{n_{i,l} + J_j - 1}\choose{J_j-1}} + log \left( { {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}} } \right) \right] + \\
& \sum_{i=1}^k \left[  log {{n_{i} + J_P - 1}\choose{J_P-1}} + log \left( { {{n_i}!}\over{ {n^{(p)}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_p} !}} } \right) \right].
\end{aligned}
\end{equation}
All parameters and variables in the objective function are explained in previous subsections.
\subsection{Algorithm}
\label{algo}
Once the objective function is established, the next problem is how to find a discretization model that minimizes the objective function. Note that the objective function is cumulative on intervals. Therefore, if a partition of continuous variable $X$ into $I$ intervals with lengths $n_1,n_2,...,n_k$ is an optimal discretization policy, then $\{ n_2, n_3,...,n_k \}$ is optimal for the subproblem, i.e., the last $N - n_1$ instances of the dataset which has been sorted in ascending order of $D_X$. With this property, we can adapt dynamical programming to solve this optimization problem.

If there is no repeated value in $D_X$, all middle points of two consecutive values can be discretization edges. If there exists repeated values in $D_X$, only the middle points of two consecutive and different values can be discretization edges. Assume there are $M$ unique values in $D_X$, then ${D'_X} = \{ x'_1,x'_2,...,x'_M \}$ are the unique values in ascending order. Since $D_X$ is also sorted, let $b = \{ b_0,b_1,b_2,...,b_M \}$ be an increasing sequence of integers such that $b_0 = 0$ and $x'_i = x_{b_{i-1} + 1} = x_{b_{i-1} + 2} = ... = x_{{b_i}}$. By this definition, the allowable discretization positions are $d_i = (x_{{b_i}+1} + x_{b_{i}})/2$ for all $i = 1,2,...,M-1$.

In order to save runtime, we first calculate the following function $g(u,v)$ for a interval $I_q$ starting from $x_{u}$ to $x_{v}$ with all $u$,$v$ satisfying $u \leq v$:
\begin{equation}
\begin{aligned}
g_p(u,v) &=  log {{n_{q} + J_P - 1}\choose{J_P-1}} + log \left( { {{n_q}!}\over{ {n^{(p)}_{q,1} !} {n^{(p)}_{q,2} !} \cdots {n^{(p)}_{q,J_p} !}} } \right) \\
g_c(u,v) &= \sum_{j=1}^{n_c} \sum_{l=1}^{L_j} \left[  log{{n_{q,l} + J_j - 1}\choose{J_j-1}} + log \left( { {{n_{q,l}}!}\over{ {n^{(j)}_{q,1,l} !} {n^{(j)}_{q,2,l} !} \cdots {n^{(j)}_{q,J_j,l} !}} } \right) \right] \\
g(u,v) &= g_p(u,v) + g_c(u,v).
\end{aligned}
\end{equation}

The evaluation of function $g_p(u,v)$ and $g_c(u,v)$ can be done as Algorithm 1 and Algorithm 2, respectively. Algorithm 2 is an illustrative version of calculation $g_c(u,v)$. The more time-efficient but structurely complicated algorithm for calculating $g_c(u,v)$ is shown in Appendix. Notice that due to repeated values in $D_X$, for some pairs of $u$ and $v$, $g(u,v)$ might depend on the sorting method. However, this doesn't influence the optimization result, since these pairs of $u$ and $v$ will not form valid intervals. Now we are able to solve the optimization problem with the objective function in Equation 14. The dynamical programming procedure is shown in Algorithm 3. As discussed before, the runtime of Algorithm 3 is $O(n_c  {v_{max}} \cdot N^2 + {v_{max}}^{n_p} \cdot N^2)$, where $v_{max}$ is the largest cardinality number of variables that directly connects $X$. There are other methods that lead to suboptimal results but runs faster than dynamical programming method. Please refer to \citep{Boulle_2006}.
\begin{algorithm}
\caption{ Calculation of function $g_p(u,v)$ for all $u \leq v$}\label{euclid}
\begin{algorithmic}[1]
\State Initialize $g_p$ as an $N$ by $N$ matrix that all elements are 0.
\State $count_p$ is an N by N by $||\Pi_X||$ matrix such that $count_p (u,v,w)$ is the number of instances from $x_u$ to $x_v$ with $w$th value of $\Pi_X$. This matrix can be calculated in $O(||\Pi_X|| \cdot N^2)$
\For {$u = 1$ to $N$}
\For {$v = u$ to $N$}
\State $g_p(u,v) \leftarrow g_p(u,v) + log((v-u + J_p)!) - log((J_p -1)!)$
\For {$w = 1$ to $||\Pi_X||$}
\State $g_p(u,v) \leftarrow g_p(u,v) - log( count_p(u,v,w)!)$
\EndFor 
\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{ Calculation of function $g_c(u,v)$ for all $u \leq v$}\label{euclid}
\begin{algorithmic}[1]
\For {$j = 1$ to $n_c$}
\State $count_j$ is an N by N by $||\boldsymbol{S_j}||$ by $||C_j||$ matrix such that $count_j (u,v,q,r)$ is the number of instances from $x_u$ to $x_v$ with $q$th value of $\boldsymbol{S_j}$ and $r$th value of $C_j$.
\For {$u=1$ to $N$}
\For {$v = u$ to $N$}
\For {$q = 1$ to $||\boldsymbol{S_j}||$}
\State $n' \leftarrow  \sum_{r=1}^{J_j} count_j (u,v,q,r)$
\State $g(u,v) \leftarrow g(u,v) + log(( v - u + 1 + n')!) - log((v-u+1)!)$
\For {$r = 1$ to $J_j$}
\State $g(u,v) \leftarrow g(u,v) - log((count_j (u,v,q,r))!)$
\EndFor
\EndFor
\EndFor
\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{ Discretization of one continuous variable}\label{euclid}
\begin{algorithmic}[1]
\State Let $S(u)$ be the optimal objective function value of a subproblem starting from instance $1$ to instance $u$.
\State Let $Disc(u)$ be the optimal discretization of a subproblem starting from instance $1$ to instance $u$.
\State Let $L(u) = - log(1 - {exp(- M \cdot {{x_{b(u)+1} - x_{b(u)}}\over{x_N - x_1}})})$ for $u = 1,2...,M-1$ and $L(M) = 0$. 
\State Calculate $g(u,v)$ for all $u \leq v$ as Algorithm 1.
\For {$v = 1$ to $M$}
\If {$v = 1$}
\State $S(v) = g \left(1,b(v) \right) + L(v)$
\State $Disc(v) = \{ ({x_{b(v)} + x_{b(v)+1}}) / 2\}$
\Else
\State $s = \infty$ and $boundary = \infty$
\For {$u = 1$ to $v$}
\State $s' \leftarrow S(u) + g \left( b(u)+1,b(v) \right) +  {M({x_{b(v)} - x_{b(u) + 1}})\over{x_N - x_1}} + L(v)$
\If {$s' < s$}
\State $s \leftarrow s'$
\State $boundary = ({x_{b(u)} + x_{b(u)+1}}) / 2$
\EndIf
\EndFor
\State $S(v) = s$
\State $Disc(v) = Disc(u) \cup \{ boundary\}$
\EndIf
\EndFor

\end{algorithmic}
\end{algorithm}

\subsection{Approximation}
\label{approx}
Notice that Algorithm1 leads to the non-polynomial runtime $O({v_{max}}^{n_p} \cdot N^2)$ in the discretization process. Therefore, we have an empirical approximation to the objective function that can reduce runtime and still preserve the quality of discretization. As shown in Section 6, the approximated algorithm is more sensitive to the distribution of other variables' values and usually leads to slightly more discretization edges. With the approximation, we can reduce runtime of Algorithm 1 from $O({v_{max}}^{n_p} \cdot N^2)$ to $O({v_{max}} \cdot {n_p} \cdot N^2)$. The rigorous proof of the approximation have not been proposed.

For the dominator of the last factor in Equation 11, we have the following approximation
\begin{equation}
{{{{n}_i}!}\over{ {{n^{(p)}}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_P} !}}} \approx \prod_{q=1}^{n_p} { {{{n}_i}!}\over{ {n^{(p_q)}_{i,1} !} {n^{(p_q)}_{i,2} !} \cdots {n^{(p_q)}_{i,J_{p_q}} !}}},
\end{equation}
where $J_{p_q} = || P_q||$ and ${n^{(p_q)}_{i,j} !}$ is the number of instances in $i$th interval with $j$th value of $P_q$. Then the calculation of corresponding approximated $g_p(u,v)$ can be done as Algorithm 4. With the approximation, the approximate objective function is
\begin{equation}
\begin{aligned}
& \sum_{i=1}^{k-1} - log(1 - {exp(- M \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}) +  \sum_{i=1}^{k} M \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}} +\\
&  \sum_{j=1}^{n_c} \sum_{i=1}^{k}  \sum_{l=1}^{L_j} \left[  log{{n_{i,l} + J_j - 1}\choose{J_j-1}} + log \left( { {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}} } \right) \right] + \\
& \sum_{i=1}^k \left[  log {{n_{i} + J_P - 1}\choose{J_P-1}} + \sum_{q=1}^{n_p} log \left( { {{{n}_i}!}\over{ {n^{(p_q)}_{i,1} !} {n^{(p_q)}_{i,2} !} \cdots {n^{(p_q)}_{i,J_{p_q}} !}}} \right) \right].
\end{aligned}
\end{equation}

\begin{algorithm}
\caption{ Calculation of approximated function $g_p(u,v)$ for all $u \leq v$}\label{euclid}
\begin{algorithmic}[1]
\State Initialize $g_p$ as an $N$ by $N$ matrix that all elements are 0.
\For {$q = 1$ to $n_p$}
\State $count_{p_q}$ is an N by N by $||P_q||$ matrix such that $count_{p_q} (u,v,w)$ is the number of instances from $x_u$ to $x_v$ with $w$th value of $P_q$. This matrix can be calculated in $O(||P_q|| \cdot N^2)$
\For {$u = 1$ to $N$}
\For {$v = u$ to $N$}
\State $g_p(u,v) \leftarrow g_p(u,v) + log((v-u + ||P_q||)!) - log((||P_q|| -1)!)$
\For {$w = 1$ to $||P_q||$}
\State $g_p(u,v) \leftarrow g_p(u,v) - log( count_p(u,v,w)!)$
\EndFor 
\EndFor
\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

With Equation 17, we have a more clear way to see that how child variables and parent variables contribute to the objective function differently. For example, in the left graph of Figure 2, the corresponding sqaure bracket in Equation 17 is
\begin{equation}
\begin{aligned}
 \sum_{i=1}^k & \left\lbrace   \left[ log{{n_{i} + J_{C_1} - 1}\choose{J_{C_1}-1}} + log \left(  {{{n_i}!} \over { {n^{(1)}_{i,1,\emptyset} !} \cdots {n^{(1)}_{i,J_{C_1},\emptyset} !}} }  \right)  +  \right. \right.\\ 
& \left.  log{{n_{i} + J_{C_2} - 1}\choose{J_{C_2}-1}} + log \left(  {{{n_i}!} \over { {n^{(2)}_{i,1,\emptyset} !} \cdots {n^{(2)}_{i,J_{C_1},\emptyset} !}} }  \right)  \right] + \\
&  \left. \left[  log {{n_{i} + J_P - 1}\choose{J_P-1}} +  log \left( { {{{n}_i}!}\over{ {n^{(p_1)}_{i,1} !}\cdots {n^{(p_1)}_{i,J_{p_1}} !}}} \right) +{ {{{n}_i}!}\over{ {n^{(p_2}_{i,1} !}\cdots {n^{(p_2)}_{i,J_{p_2}} !}}}  \right] \right\rbrace\\ .
\end{aligned}
\end{equation}
In Equation18, each child variable carries two terms as the first square bracket, and two parent variables only carry three terms as the second square bracket. Therefore, in this case, child variables are more determinative than parent variables, even though the number of child variables is same as the number of parent variables. However, if $C_2$ has another parent variables, as shown in the right graph of Figure 2, the importances of $C_2$ will be debiliated, since the information from $C_2$ is now adulterated by $S_2$. These argument shows that our proposed method, either before or after approximation, indeed involves graph structures to discretize continuous variables.


\begin{figure}
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[width=9cm]{graph2.png}
% figure caption is below the figure
\caption{Two example networks}
\label{fig:2}       % Give a unique label
\end{figure}

\section{Discretizing Multiple Continuous Variable with Structure Learning}
\label{DMC_SL}
\subsection{Discretization of Multiple Continuous Variables}
\label{DMC}
If there are multiple continuous variables in a Bayesian network, we iterate the one-variable discretization method discussed above for all continuous variables. While discretizing a continuous variable, other continuous variables must be discretized, either by prediscretization before the iteration starts or by the discretization results of previous iteration. The prediscretization here can be done by equal-width discretization, which is defined as follows:
\begin{equation}
M_X =  \{ min_X, min_X + \delta, min_X + 2\delta, ..., \delta, max_X \},
\end{equation}
where $min_X$ and $max_X$ are minimal and maximal values of $D_X$, respectively, $\delta =  (max_X - min_X)/k$ and $k$ is the desired number of intervals after equal-width discretization. $k$ is same for all continuous variables and is set to be median value of all discrete variables' cardinalities. After prediscretization, we iterate the one-variable discretization on each continuous variable in the following order: from the continuous variable with highest topological order (leaves) to the continuous variable with lowest topological order (root). We call a series of the iterations that follows this order one time as a cycle. The advange of the order is that, for the first cycle of iteration, we can use less number of unsupervised discretization result. For example, in the right graph of Figure 2, assume $S_2$ is the only discrete variable. If we begin the iteration with $P_1$, then the discretization of $P_1$ will involve the prediscretization results of $P_2$ and $X$. However, if we begin the iteration with $C_1$, then the discretization of $C_1$ will only involve the prediscretization result of $X$.

We stop the iterations and output the discretization result on each continuous variable when the number of intervals and the positions of discretization edges converge. Since the convergence is not guaranteed, we also set up a maximal number of cycles to prevent infinite iterations. In our test on real-world data, the iteration results usually converge within few cycles. Even if it does not converge, 10 cycles usually produce good enough discretization result. The summary of multi-variable discretization is shown as Algorithm 5.


\begin{algorithm}
\caption{ Discretization of multiple continuous variables}
\begin{algorithmic}[1]
\State Let $Disc(i)$ is the discretization on $i$th continuous variable. If variable $i$ is discrete, $Disc(i)$ contains no information. 
\State Let $D^*_i$ is the discrete data of $i$th variable. If variable $i$ is continuous, then $D*_i$ is discretized $D_i$ by $Disc(i)$.
\State Let $C$ be the set of continuous variables in a reverse topological order.
\State Let $n$ be the number of variables in the given Bayesian network, $k$ is the largest cardinality number of discrete variables.
\State \% Prediscretize continuous variables, $bound_{cycle}$ is the upper bound of cycles.
\For {$i = 1$ to $n$}
\If {$i \in C$}
\State {$Disc(i)$ = prediscretization result of $k$ intervals}
\EndIf
\EndFor
\State \% Iterate one-variable discretization until converge
\State $cycle = 0$
\While {$Disc$ is not converged  $\&$ $cycle \leq bound_{cycle}$}
\State {$cycle  \leftarrow cycle  + 1$}
\For {$j = 1$ to $||C||$}
\State {Let $D^*_{\backslash C(j)}$ be the discrete data of all variables except $D^*_{C(j)}$.}
\State {$Disc(C(j)) = $ one-varaible discretization result with $D_{C(j)}$ and  $D^*_{ \backslash C(j)}$.}
\State {$D^*_{C(j)} =$ the discretized data of $D_{C(j)}$ by lastest discetization policy $Disc(C(j)) $}
\EndFor
\EndWhile
\end{algorithmic}
\end{algorithm}

\subsection{Discretization of Continuous Variables While Structure Learning}
\label{SL}


\section{Experiments}




%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
%\begin{thebibliography}{}
\bibliographystyle{plainnat}
\bibliography{my_bib}

\section*{Appendices}
\end{document}
% end of file template.tex

