%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
  %!PS-Adobe-3.0 EPSF-3.0
  %%BoundingBox: 19 19 221 221
  %%CreationDate: Mon Sep 29 1997
  %%Creator: programmed by hand (JK)
  %%EndComments
  gsave
  newpath
    20 20 moveto
    20 220 lineto
    220 220 lineto
    220 20 lineto
  closepath
  2 setlinewidth
  gsave
    .4 setgray fill
  grestore
  stroke
  grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[round]{natbib}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepgfplotslibrary{groupplots}
\usepackage{tikz}
\usepackage{lscape}
\usepackage{caption}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{boondox-cal} % for lowercase caligraphic
% \usepackage[capitalize]{cleveref}
\usetikzlibrary{bayesnet}
\setcitestyle{aysep={ }} %Author-Year Separator
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%
\pgfplotsset{
    jitter/.style={
        x filter/.code={\pgfmathparse{\pgfmathresult+rnd*#1}}
    },
    jitter/.default=0.1
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CUSTOM COMMANDS

\newcommand{\bigo}{O} % NOTE(tim): if you prefer normal O change it here.

\newcommand{\paren}[1]{\mathopen{}\mathclose\bgroup\left(#1\aftergroup\egroup\right)}
\newcommand{\brock}[1]{\mathopen{}\mathclose\bgroup\left[#1\aftergroup\egroup\right]}
\newcommand{\curly}[1]{\mathopen{}\mathclose\bgroup\left\{#1\aftergroup\egroup\right\}}
\newcommand{\anglebrackets}[1]{\langle #1 \rangle}
\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\todo}[1]{\textcolor{magenta}{#1}}
\newcommand{\yichun}[1]{\textit{\textcolor{green}{#1}}}
\newcommand{\tim}[1]{\textit{\textcolor{blue}{#1}}}
\newcommand{\mykel}[1]{\textit{\textcolor{cyan}{#1}}}

\DeclareMathOperator{\Pa}{pa} % parents of a var in a BN
\newcommand{\cX}{\mathcal{X}} % continuous X
\newcommand{\cx}{\mathcal{x}} % instance of x
\newcommand{\cu}{\mathcal{u}} % unique sorted instances of x
\newcommand{\maxpasses}{\hat{n}_\text{cycle}}
\newcommand{\discset}{\Lambda_{\bm{\cX}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Learning Discrete-valued Bayesian Networks from Mixed Data%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Yi-Chun Chen           \and
        Tim A. Wheeler         \and
        Mykel J. Kochenderfer
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{Yi-Chun Chen \at
              Institute of Computational and Mathematical Engineering, Stanford University \\
              \email{yichunc@stanford.edu}
           \and
              Tim A. Wheeler \at
              Department of Aeronautics and Astronautics, Stanford University\\
              \email{wheelert@stanford.edu}
           \and
              Mykel J. Kochenderfer \at
              Department of Aeronautics and Astronautics, Stanford University\\
              \email{mykel@stanford.edu}
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor

\maketitle

\begin{abstract}

Real data often contains a mixture of discrete, continuous, and hybrid variables, but many Bayesian network structure learning and inference algorithms assume all random variables are discrete.
Continuous and hybrid variables are often discretized, but the choice of discretization policy has significant impact on the accuracy, speed, and interpretability of the resulting models.
This paper introduces a principled discretization method for continuous variables in Bayesian networks with quadratic complexity instead of the cubic complexity of other standard techniques.
Emperical demonstrations show that the proposed method is superior to the state of the art.
In addition, this paper shows how to incorporate existing methods into the structure learning process to discretize all continuous variables and simultaneously learn Bayesian network structures.
The proposed method was incorporated and its superior performance was empirically demonstrated.
All software is publically available to support discretization research.

\keywords{Discretization \and Bayesian Network \and Continuous Variable \and }
  % \PACS{PACS code1 \and PACS code2 \and more}
  % \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Bayesian networks \citep{Pearl_1988, PGM_2009} are an increasingly popular method for modeling uncertainty and causality in science and engineering.
They provide an efficient factorization of the joint probability distribution over a set of random variables.
Bayesian networks first emerged from artificial intelligence research and have been applied to a wide variety of problems, ranging from decision-making systems \citep{kochenderfer2012next} to medical diagnoses \citep{Lustgarten_2011}.
In many application, it is assume that all random variables in Bayesian networks are discrete, since many Bayesian network algorithms are unable to deal with continuous variables efficiently. In addition, many of the commonly used Bayesian network software packages, such as Netica \citep{netica1992}, SMILearn \citep{druzdzel1999smile}, and bnlearn \citep{bnlearn2010}, are geared towards discrete variables. However, various applications require the use of continuous variables, such as position and velocity in dynamic systems \citep{kochenderfer2010airspace}.

There are three common approaches to extending Bayesian networks to continuous variables.
The first is to model the conditional probability density of each continuous variable using specific families of parametric distributions, and then to redesign Bayesian network learning algorithms based on their parameters.
One successful example are Gaussian graphical models \citep{Weiss_2011}.
For other parametric distributions and non-linear functions \citep{Ihler_2009}, these redesigned algorithms are computationally expensive and do not perform well.
The second is to use nonparametric distributions, such as particle representations and Gaussian processes \citep{Ickstadt_2010}.
Unlike parametric methods, nonparametric methods do not make assumptions about the probability distributions being used.
Parametric models have a fixed number of parameters, whereas the number of parameters in a nonparametric model grow with the amount of training data.

The third approach is discretization.
Automated discretization methods have been studied in machine learning and statistics for many years \citep{Dougherty_1995, Kerber_1992, Holte_1993, Fayyad_1993}, primarily for classification problems.
They search for the best discretization policy of a continuous attribute by considering its interation with the target class variable.
Interations and dependencies between variables in Bayesian networks are more complicated, where discretization requires considering the impact on the variable's Markov blanket.
Prior work exists for discretizing continuous variables in naive Bayesian networks and tree-augmented networks \citep{Fried_naive}, but only a few discretization methods for general Bayesian networks have been proposed \citep{Friedman_1996, Kozlov_1997, Monti_1998, Steck_2007}.


This work is primarily concerned with the minimum description length (MDL) principle discretization \citep{Friedman_1996} and MODL discretization \citep{Boulle_2006} methods.
The former is the predominant discretization method for continuous variables in Bayesian networks, and is compared to our proposed Bayesian method in Section~\ref{sec:experiments}.
The latter is a Bayesian discretization method for one continuous variable against a discrete target class, which our proposed method generalizes to Bayesian networks.
The asymptotical equivalence between MDL and MODL was examined in \citep{VL_2000}.

The MDL principle was first proposed by \cite{MDL_1978} and states that the best model for a dataset is one that minimizes the amount of information needed to describe it \citep{Grunwald_2009}.
MDL methods trade off goodness-of-fit against model complexity to reduce generalization error.
In the context of Bayesian networks, \cite{Friedman_1996} applied the MDL principle to determine the optimal number of discretization intervals for continuous variables and the optimal positions of their discretization edges.
Their approach selects a discretization policy that minimizes the sum of the description lengths of the discretized Bayesian network and the information necessary for recovering the continuous values from the discretized data.
Results in this work suggest that the MDL method suffers from low sensitivity to discretization edges and returns low numbers of discretization intervals on continuous variables.

The optimal discretization policy is found with dynamic programming, and it takes runtime $\bigo\paren{n^3 + q \cdot n^2}$, where $n$ is the number of data instances and $q$ is a constant that exponentially depends on cardinalities of variables in Bayesian networks and will be discussed in Section \ref{sec:experiments}.
For Bayesian networks with multiple continuous variables, MDL discretization is iteratively applied to each continuous variables.
While iterating, only one variable is treated as continuous while all other continuous variables are treated as discretized based on an initial discretization policy or the discretization result from a previous iteration.

The network structure is not always known in advance.
Bayesian network structure learning can be extended to distributions including continuous variables by alternating between traditional discrete structure learning and optimal discretization.
Starting with some preliminary discretization policy, one applys a structure learning algorithm to identify the locally optimal graph structure.
The discretization policy is refined based on the learned network.
The cycle is continued until convergence.

MODL discretization \citep{Boulle_2006} is a Bayesian method for discretizing a continuous feature according to a class variable.
Bayesian methods maximize the probability of the model given the data, $P(\textit{Model} \mid \textit{Data})$.
An application of Bayes' rule and constant $P(\textit{Data})$ shows that this is equivalent to maximizing ${P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model})}$, where $P(\textit{Model})$ is a prior over models and ${P(\textit{Data} \mid \textit{Model})}$ is the data likelihood.
The data likelihood usually increases with the number of discretization intervals, as more intervals allow for richer representations.
The prior is chosen to decrease as the number of discretization intervals increases to favor simpler models and prevent overfitting.
Maximizing ${P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model})}$ requires a trade-off when determining the number of discretization intervals.

The MODL method uses dynamic programming to find the optimal discretization policy, and has an $\bigo\paren{n^3 + r \cdot n^2}$ runtime, where $r$ is the number of instances for the class variable.
\cite{Lustgarten_2011} suggest several formulations for the prior term $P(\text{Model})$.
Under a uniform prior probability over discretizations the runtime can be reduced to $\bigo\paren{r \cdot n^2}$ without sacrificing optimality.

This paper describes a new Bayesian discretization method for continuous variables in Bayesian networks, extending prior work on single-variable discretization methods from \citet{Boulle_2006} and \citet{Lustgarten_2011}.
The proposed method optimizes the discretization policy relative to the network and takes parents, children, and spouse variables into account.
The optimal single-variable discretization method is derived in Section~\ref{sec:single_var}.
Section~\ref{sec:multi_var} covers Bayesian networks with multiple continuous variables and discretization while simultaneously learning network structure.
The paper concludes with a comparison against the existing minimum-description length \citep{Friedman_1996} method on real-world datasets in Section~\ref{sec:experiments}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}
\label{sec:preliminaries}
This section covers the notation used throughout the paper and provides a brief overview of Bayesian networks, including the factorization of joint probability distributions, sampling from a Bayesian network, and structure learning.
These concepts will be used in later sections.
The formal definition of a discretization policy for a continuous variable is also given.

\subsection{Bayesian Networks and Sampling}

A Bayesian network $B$ is defined by a pair $(G,\bm{\theta})$, where $G$ is a directed acyclic graph whose $N$ nodes $X_{1:N}$ are random variables.
The edges in a Bayesian network represent probabilistic dependencies among nodes and encode the Markov property: each node $X_i$ is independent of its non-descendants given its parents $\Pa_{X_i}$ in $G$.
For a Bayesian network over discrete and discretized variables, $r_i$ represents the number of instantiations of $X_i$, and $q_i$ represents the number of instantiations of the parents of $X_i$.
If $X_i$ has no parents, then $q_i = 1$.
The $j$th instantiation of the parents of $X_i$ is denoted $\bm{\pi}_{ij}$.

The conditional relations are parameterized by the elements of $\bm{\theta}$, written $\theta_{ij}^{(k)}$, which determines

\begin{equation}
P(X_i = k \mid \bm{\pi}_{ij}) = \theta_{ij}^{(k)}\text{.}
\end{equation}

The joint distribution over the variables in the Bayesian network factors according to the Markov property:

\begin{equation}
P(X_{1:N}) = \prod_{i=1}^N P(X_i \mid \Pa_{X_i})\text{.}
\end{equation}

Forward sampling is often used to draw samples from the joint distribution represented by a Bayesian network.
Variables are sampled in topological order such that parental instantiations are always known~\citep{PGM_2009}.
Furthermore, the parent $\rightarrow$ child sampling order can be reversed if the marginal probability of the child variable is known.
% By Bayes' rule,

% \begin{equation}
% P(X_i \mid \Pa_{X_i}) \cdot \prod_{Y \in \Pa_{X_i}} P(Y) = P(X_i) \cdot P(\Pa_{X_i} \mid X_i)\text{.}
% \end{equation}

\subsection{Structure Learning}

It is often necessary to infer the structure of a Bayesian network from data.
Three common approaches to Bayesian network structure learning are constraint-based, score-based, and Bayesian model averaging \citep[see][chap.~18]{PGM_2009}.
This work uses the K2 structure learning algorithm \citep{K2}, one of the most successful score-based structure learning methods.
Score-based structure learning methods over discrete variables commonly evaluate candidate structures according to their likelihood against a dataset $D$.
Let $\beta_{ij}^{(k)}$ be the number of times $X_i = k$ given $\bm{\pi}_{ij}$ in $D$.
The likelihood is given by

\begin{equation}
P(D\mid \bm{\theta}, G) = \prod_{i=1}^N \prod_{j=1}^{q_i} \prod_{k=1}^{r_i} \brock{\theta_{ij}^{(k)}}^{\beta_{ij}^{(k)}}\text{.}
\end{equation}


Structure search for a Bayesian network seeks the graph structure $G$ that maximizes ${P(G\mid D)}$.
In practice one maximizes the log-likelihood, also known as the Bayesian score~\cite{cooper1992bayesian}:

\begin{small}
\begin{equation}
\label{eq:BayesianScore}
  \ln P(D\mid G) = \ln P(G) + \sum_{i=1}^N \sum_{j=1}^{q_i} \ln \paren{
    \frac{
      \Gamma\paren{\alpha_{ij}^{(0)}}
    }{
      \Gamma\paren{\alpha_{ij}^{(0)} + \beta_{ij}^{(0)}}
    }
  } + \sum_{k=1}^{r_i} \ln \paren{
    \frac{
      \Gamma\paren{\alpha_{ij}^{(k)} + \beta_{ij}^{(k)}}
    }{
      \Gamma\paren{\alpha_{ij}^{(k)}}
    }
  }\text{.}
\end{equation}
\end{small}

In the equation above,

\begin{equation}
\alpha_{ij}^{(0)} = \sum_{k=1}^{r_i} \alpha_{ij}^{(k)} \quad \qquad \beta_{ij}^{(0)} = \sum_{k=1}^{r_i} \beta_{ij}^{(k)}\text{.}
\end{equation}

The space of acyclic graphcs is superexponential in the number of nodes so it is common to rely on heuristic search strategies \citep{PGM_2009}.
The K2 algorithm assumes a topological ordering of variables and greedily adds parents to nodes to maximally increase the Bayesian score.
A fixed ordering ensures acyclicity but does not guarantee a globally optimal network structure.
K2 is typically run multiple times with random variable orderings and the network with the highest likelihood is retained.

\subsection{Discretization Policies}
\label{subsec:disc_policy}

Let $\cX$ be a continuous variable and let $\cx$ be a specific instance of $\cX$.
A discretization policy $\Lambda_{\cX} = \anglebrackets{e_1 < e_2 < \ldots < e_{k-1}}$ for $\cX$ is a mapping from $\mathbb{R}$ to $\curly{1,2,3,\ldots,k}$ such that

\begin{equation}
  \Lambda_{\cX}(\cx) = \begin{cases}
    1, & \text{if $x<e_1$}\\
    i, & \text{if $e_{i-1} \leq x < e_i$}\\
    k, & \text{otherwise.}
  \end{cases}
\end{equation}

\noindent
The discretization policy discretizes $\cX$ into $k$ intervals.
Let the samples of $\cX$ in a given dataset $D$ be sorted in ascending order, ${\cx_{1:n} = \curly{\cx_1 \leq \cx_2 \leq \ldots \leq \cx_n}}$, and let the unique values be ${\cu_{1:m} = \curly{\cu_1 \leq \cu_2 \leq \ldots \leq \cu_{m}}}$.
The index of the last occurence of $\cu_i$ in $\cx_{1:n}$ is denoted $s_i$.

The discretization edges $e_{1:k-1}$ mark the boundaries between discretization intervals.
In this work they are restricted to the midpoints between unique ascending instances of $\cX$.
Thus, each edge $e_i = \paren{\cu_{j} + \cu_{{j+1}}}/2$ for some $j$.
Two useful integer representations of $\Lambda_{\cX}$ can be written

\begin{equation}
\label{eq:disc_def}
  \Lambda_{\cX} = \anglebrackets{\lambda_1 < \lambda_2  < \ldots < \lambda_k} \equiv \anglebrackets{\gamma_1 , \gamma_2  , \ldots , \gamma_k}\text{,}
\end{equation}

\noindent
where $\lambda_1 = s_1$, $\lambda_i \in s_{1:m}$, $\gamma_1 = \lambda_1$, and $\gamma_i = \lambda_i - \lambda_{i-1}$.
The $\lambda_{1:k}$ representation is the number of instances before every discretization edge whereas the $\lambda$ representation is the number of instances within each discretization interval.

Finally, when discussing the discretization of a particular continuous variable $\cX$, let $P_i$ be the $i$th parent of $\cX$, let $C_i$ be the $i$th child of $\cX$, and let $\bm{S}_i$ be set of spouses of $\cX$ corresponding to the $i$th child.
Context should make it clear when $P$ refers to a discrete probability and when it refers to a variable's parent.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Single Variable Discretization}
\label{sec:single_var}

This section covers the discretization of a single continuous variable $\cX$ in a Bayesian network where all other variables are discrete.
An optimal discretization policy for a dataset $D$ maximizes $P(\Lambda)\cdot P(D\mid \Lambda)$ for some prior $P(\Lambda)$ and likelihood $P(D\mid \Lambda)$.

% Let $n_p$ and $n_c$ respectively refer to the number of parents and number of children of $X$.

% Let $D$ be a dataset of $N$ samples from which the discretization will be learned, sorted in ascending order according to $X$.
% Let $D_{\boldsymbol{Y}}$ will refer to the data instances associated with variables $\boldsymbol{Y}$, thus $D_X = \{ x_1,x_2,x_3,\ldots,x_n \}$.
% In order to facilitate understanding, we temporarily assume all values in $D_X$ are unique, that is, $x_1 < x_2 < \ldots < x_n$.
% It follows that a discretization policy $\Lambda$ on $X$ can be written as $M_X = \brock{n_1,n_2,\ldots,n_k}$, where $k$, $n_1$, $n_2$, $\ldots,n_k$ are positive integers satisfying $N = \sum_{i=1}^k n_i$.

%Furthermore, since there might have repeated values for $D_x$, we assume there are $N'$ unique values of $D_x$ and $N' \leq N$. Note that the allowable discretization edges happens between two consective values of non-repeated value of $D_x$. For example, if $D_X = \{ 1.0,1.0,2.0\}$, then the only possible discretization edge is on $1.5$.


\subsection{Priors and Objective Function}

Let $D_{\bm{Y}}$ be the subset of the data corresponding to $\bm{Y}$.
Four principles for the optimal discretization policy enable the formulation of $P(\Lambda)$ and $P(D_{-\cX} \mid \Lambda)$, where $D_{-\cX}$ is the subset of the dataset for all variables but $\cX$ and the probability of the data associated with the target variable $P(D_{\cX})$ is already captured in $P(\Lambda)$.
The four principles, motivated by MODL and \cite{Lustgarten_2011}, are:

\begin{enumerate}
\item The prior probability of a discretization edge between two consecutive unique values $\cu_i$ and $\cu_{i+1}$ is proportional to their difference:

  \begin{equation}
  1 - {\exp(- L \cdot {\frac{\cu_{i+1} - \cu_i}{\cu_m - \cu_1}})}\text{,}
  \end{equation}

where $L$ is the largest number of intervals among discrete variables in $\cX$'s Markov blanket.
This encourages edges between well-separated values over edges between closely packed samples.

\item For a given discretization interval, every distribution over $\Pa_{\cX}$ is equiprobable.
\item For each pair $\anglebrackets{C_i,\bm{S}_i}$ and a given discretization interval, every distribution over $C_i$ given an instance of $\bm{S}_i$ is equiprobable.
\item The distributions over each child and each parent in each discretization interval with each instance of $\bm{S}_i$ are independent from each other.
\end{enumerate}

From the first principle one obtains the $P(\Lambda)$ of $\Lambda$ described in Equation~\ref{eq:disc_def}

\begin{small}
\begin{equation}
  \label{eq:p_M}
  P(\Lambda) = \prod_{i=1}^{k-1}
    \brock{
      1 - \exp\paren{
        - L \cdot \frac{
                         \cx_{\lambda_i +1} - \cx_{\lambda_i}
                       }{
                         \cx_n - \cx_1
                        }
      }
    }
    \prod_{i=1}^{k}
	\brock{
    \exp\paren{
      -L \cdot \frac{\cx_{\lambda_{i}} - \cx_{\lambda_{i-1} + 1}}{\cx_n - \cx_1}}
    }\text{.}
\end{equation}
\end{small}

The Bayesian network graph structure causes the likelihood term $P(D_{-\cX} \mid \Lambda)$ to factorizes according to $\cX$'s Markov blanket:

\begin{equation}
  \label{eq:p_D_given_M}
  P\paren{D_{-\cX} \mid \Lambda} \propto P\paren{D_{\Pa_\cX} \mid \Lambda} \cdot \prod_{i} P\paren{D_{C_i} \mid \Lambda, D_{\bm{S}_i}}\text{.}
\end{equation}

For example, in Figure~\ref{fig:example_factorization}, $P(D_{-\cX} \mid \Lambda)$ factors according to

\begin{equation}
  P\paren{D_{P_1,P_2,P_3} \mid \Lambda} \cdot P\paren{ D_{ C_1 } \mid \Lambda, D_{\bm{S}_1} } \cdot P\paren{D_{C_2} \mid \Lambda, D_{\bm{S}_2}}\text{.}
\end{equation}

\begin{figure}[ht]
  \centering
  \input{graph1}
  \caption{Factorization of $P(_{-\cX} \mid \Lambda)$}
  \label{fig:example_factorization}
\end{figure}

The concept behind the factorization is also the motivation behind forward sampling in a Bayesian network.
The parents of $\cX$ are independent of the children given $\cX$.
The parents are not necessarily individually independent, and thus the parental term $P(D_{\Pa_{\cX}} \mid \Lambda)$ cannot be factored further.
The children of $\cX$ are similarly independent given $\cX$ and the corresponding spouses, leading to their factored product $\prod_{C_i} P(D_{C_i} \mid \Lambda, D_{\bm{S}_i})$.
Each component in the decomposition can be evaluated given a discretization policy and a dataset.

\subsubsection{Evaluation of $P\paren{D_{\Pa_{\cX}} \mid \Lambda}$}

Let $J_P$ be the number of instantiations of the parents of $\cX$, and let $n^{(P)}_{i,j}$ be the number of instances of $\cX$ within the $i$th discretization interval of $\Lambda$ given the $j$th parental instantiation.
Note that $\gamma_i = \sum_j n^{(P)}_{i,j}$.
It follows that

\begin{equation}
  \label{eq:likelihood_one}
  P\paren{D_{\Pa_{\cX}} \mid \Lambda} = \overbrace{\prod_{i=1}^k}^{\text{Principle 4}}
    \overbrace{\rule{0pt}{2em}
      \frac{1}{{{\gamma_i + J_P - 1}\choose{J_P - 1}}}
      \frac{1}{
        \frac{
          {\gamma_i}!
        }{
          {n^{({P})}_{i,1}}! \; {n^{({P})}_{i,2}}! \; \cdots \; {n^{({P})}_{i,J_P}}!
        }
      }
    }^{\text{Principle 2}}\text{.}
\end{equation}

The two factors on the right hand side comes from the second principle: all distributions of values of $\Pa_{\cX}$ in a given interval are equiprobable.
According to the fourth principle, the distribution in each interval is independent, so the two factors can be multiplied together.

\subsubsection{Evaluation of $P(D_{C_j} \mid \Lambda, D_{\bm{S}_j})$}
Let $J_{C_j}$ be the number of instantiations of the $j$th child of $\cX$, let $J_S^{(j)}$ be the number instantiations of the $j$th spouse set $\bm{S}_j$, and let $n^{(j)}_{i,m,l}$ be the number of instances of $\cX$ in the $i$th discretization interval of $\Lambda$ given the $m$th instantiation of $C_j$ and the $l$th instantiation of $\boldsymbol{S_j}$.
Let ${n^{(j)}_{i,l} = \sum_{m=1}^{J_j} n^{(j)}_{i,m,l}}$.
Note that ${\gamma_i = \sum_l n^{(j)}_{i,l}}$ for all $j$.
It follows that

\begin{equation}
  \label{eq:likelihood_two}
  P(D_{C_j} \mid \Lambda, D_{\bm{S}_j}) =
  \overbrace{\prod_{i=1}^{k} \prod_{l=1}^{J_S^{(j)}}}^{\text{Principle 4}}
    \overbrace{\rule{0pt}{2.3em}
      {
        \frac{1}{
          {{n^{(j)}_{i,l} + J_{C_j} - 1}\choose{J_{C_j}-1}}}
        }
        {\frac{
          1
        }{
          \frac{
            {n^{(j)}_{i,l}}!
          }{
            {n^{(j)}_{i,1,l}!} \; {n^{(j)}_{i,2,l}!} \; \cdots \; {n^{(j)}_{i,J_{C_j},l}!}
          }
        }
      }
    }^{\text{Principle 3}}
    \text{.}
\end{equation}

The two factors on the right hand side come from the third principle: all distribution of values of $C_j$ in a given interval and with a given value of $S_j$ are equiprobable.
According to the fourth prior, these distributions are independent from each other, and one can thus take their product.
If $\bm{S}_j = \emptyset$, then Equation~\ref{eq:likelihood_two} is equivalent to

\begin{equation}
  \label{eq:likelihood_three}
  P(D_{C_j} \mid \Lambda) =
  \overbrace{\prod_{i=1}^{k}}^{\text{Principle 4}}
  \overbrace{{
    {1}\over{
      {\gamma_i + J_{C_j} - 1}\choose{J_{C_j}-1}}
    }
    {{1}\over{
      {{\gamma_i}!} \over {
        {n^{(j)}_{i,1,\emptyset}!} \; {n^{(j)}_{i,2,\emptyset}!} \; \cdots \; {n^{(j)}_{i,J_{C_j},\emptyset} !}
      }
    }
  }}^{\text{Principle 3}}
  \text{,}
\end{equation}

\noindent
where $n^{(j)}_{i,m,\emptyset}$ is the number of instances of $\cX$ in the $i$th discretization interval of $\Lambda$ given the $m$th instantiation of $C_j$.

The objective function can be formulated given equations~\ref{eq:p_M},~\ref{eq:p_D_given_M},~\ref{eq:likelihood_one}, and~\ref{eq:likelihood_three}.
The log-inverse of $P(\Lambda) \cdot P(D_{-\cX} \mid \Lambda)$ is minimized for computational convenience:

\begin{equation}
\label{eq:opt_prob}
\begin{aligned}
  & \sum_{i=1}^{k-1}
   - \ln
    \paren{
      1 - \exp
      \paren{
        - L \cdot  \frac{
                         \cx_{\lambda_i +1} - \cx_{\lambda_i}
                       }{
                         \cx_n - \cx_1
                        }
      }
    }
      + \sum_{i=1}^{k}
      L \cdot \frac{\cx_{\lambda_{i}} - \cx_{\lambda_{i-1} + 1}}{\cx_n - \cx_1} + \\
  & \sum_{i=1}^{k} \brock{
  \ln{{\gamma_i + J_P - 1}\choose{J_P - 1}}
  +{ \ln \paren{
        \frac{
          {\gamma_i}!
        }{
          {n^{({P})}_{i,1}}! \; {n^{({P})}_{i,2}}! \; \cdots \; {n^{({P})}_{i,J_P}}!
        }
      }}
  } \\
  & \sum_{j=1}^{n_c} \sum_{i=1}^k \sum_{l=1}^{J^{(j)}_S} \brock{
  { \ln
          {{n^{(j)}_{i,l} + J_{C_j} - 1}\choose{J_{C_j}-1}}}
    +
    \ln \paren{ {
          \frac{
            {n^{(j)}_{i,l}}!
          }{
            {n^{(j)}_{i,1,l}!} \; {n^{(j)}_{i,2,l}!} \; \cdots \; {n^{(j)}_{i,J_{C_j},l}!}
          }
        }
        } }
\end{aligned}
\end{equation}

All parameters and variables in the objective function are explained in previous subsections.

\subsection{Algorithm}
\label{subsec:algo}

This section describes the procedure used to minimize the objective function.
Note that the objective function is cumulative over intervals, thus, if a partition of $X$ into $k$ intervals by $\Lambda = \curly{\gamma_1 , \gamma_2  , \ldots , \gamma_k}$ is an optimal discretization policy, then any subinterval is optimal for the corresponding subproblem.
It follows that dynamic programming can be used to solve the optimization problem exactly.

Precomputation reduces runtime.
Compute $h(u,v)$ for each interval $\gamma_q$ starting from $x_{u}$ to $x_{v}$ for all $u$, $v$ satisfying $u \leq v$:

\begin{small}
  \begin{equation}
  \label{eqn:h_function}
  \begin{aligned}
  h(u,v) &=  \ln {{\gamma_{q} + J_P - 1}\choose{J_P-1}} + \ln \left( { {{\gamma_q}!}\over{ {n^{(p)}_{q,1} !} {n^{(p)}_{q,2} !} \cdots {n^{(p)}_{q,J_p} !}} } \right) \\
  & + \sum_{j=1}^{n_c} \sum_{l=1}^{J^{(j)}_S} \brock{
    { \ln
            {{n^{(j)}_{i,l} + J_{C_j} - 1}\choose{J_{C_j}-1}}}
      +
      \ln \paren{ {
            \frac{
              {n^{(j)}_{i,l}}!
            }{
              {n^{(j)}_{i,1,l}!} \; {n^{(j)}_{i,2,l}!} \; \cdots \; {n^{(j)}_{i,J_{C_j},l}!}
            }
          }
          } }
  \end{aligned}
  \end{equation}
\end{small}

The calculation of $h(u,v)$ for all $u \leq v$ has a $\bigo \paren{ n_c \cdot {L}^{n_s} \cdot n^2 + {L}^{n_p} \cdot n^2 }$ runtime, where $n_c$ and $n_p$ are the numbers of child and parent variables respectively, $L$ is the largest cardinality of variables in $X$'s Markov blanket, and $n_s = \text{max}_j  |\Pa_{C_j}|$.

The optimization problem over Equation~\ref{eq:opt_prob} can now be solved.
The dynamic programming procedure is shown in Algorithm~\ref{alg:disc_one}.
It takes three inputs: $\cX$, the continuous variable; $D$, the joint data instances over all variables sorted in ascending order according to $D_X$; and $G$, the network structure.
The runtime of Algorithm~\ref{alg:disc_one} is also $\bigo \paren{ n_c \cdot {L}^{n_s} \cdot n^2 + {L}^{n_p} \cdot n^2 }$, because the runtime of the dynamic programming procedure is less than the runtime for computing $h(u,v)$.
Algorithm~\ref{alg:disc_one} is guaranteed to be optimal.
For faster methods with suboptimal results please refer to the work of \cite{Boulle_2006}.

\begin{algorithm}
  \caption{Discretization of one continuous variable in a Bayesian network}
  \label{alg:disc_one}
  \begin{algorithmic}[5]
    \Function{DiscretizeOne}{$D$, $G$, $\cX$}
      % \State $n \leftarrow$ the number of data instances
      % \State $m \leftarrow$ the number of unique values in $D_{\cX}$
      \State $H \leftarrow$ an $n \times n$ matrix such that $H[u,v] = h(u,v)$; can be precomputed
      % \State $s_{1:m} \leftarrow$ an increasing sequence of integers defined in Section~\ref{subsec:disc_policy}; can be precomputed
      \State $L \leftarrow$ the largest cardinality over all discrete variables in the Markov blanket of $\cX$
      \State $S[i] \leftarrow$ the optimal objective value computed over samples $1$ to $s_i$
      \State $\Lambda[i] \leftarrow$ the discretization policy for the subproblem over samples $1$ to $s_i$
      \State $W[i]  \leftarrow - \ln\brock{1 - {\exp\paren{- L \cdot{ {{\cx_{s_i+1} - \cx_{s_i}}\over{\cu_m - \cu_1}}}}}}$ for $i \in [1,m-1]$ and $W[m] \leftarrow 0$
      \For {$v \leftarrow 1$ to $m$}
        \If {$v = 1$}
          \State $S[v] \leftarrow H \paren{1,s_v} + L[v]$
          \State $\Lambda[v] \leftarrow \curly{({\cu_v + \cu_{v+1}}) / 2}$
        \Else
          \State $\hat{S}, \hat{u} \leftarrow \infty, 0$
          \State $\text{DiscEdge} \leftarrow \infty$
          \For {$u \leftarrow 1$ to $v$}
            \If {$u = v$}
              \State $\tilde{S} \leftarrow W[v] + H \paren{1, s_v} +  {L \cdot {\frac{\cu_{v} - \cu_1}{\cu_m - \cu_1}}}$
            \Else
              \State $\tilde{S} \leftarrow W[v] + H \paren{s_u+1, s_v} +  {L \cdot {\frac{\cu_{v} - \cu_{u + 1}}{\cu_m - \cu_1}}} + S[u]$
            \EndIf
            \If {$\tilde{S} < \hat{S}$}
              \State $\hat{S}, \hat{u} \leftarrow \tilde{S}, u$
              \State $\text{DiscEdge} \leftarrow ({x_{s_u} + x_{s_u+1}}) / 2$
            \EndIf
          \EndFor
          \State $S[v] \leftarrow \hat{S}$
          \State $\Lambda[v] \leftarrow \Lambda[u] \cup \{ \text{DiscEdge} \}$
        \EndIf
      \EndFor
      \State \Return $\Lambda[m]$
    \EndFunction
  \end{algorithmic}
\end{algorithm}


% \subsection{Approximation}

% Algorithm~\ref{alg:disc_one} has an exponential $\bigo\paren{\paren{L'}^{n_p} \cdot N^2}$ runtime which severely limits discretization in networks with a large number of discretization intervals or parent variables.
% This section introduces an approximation to the objective function that significantly reduces the runtime and still preserves the quality of discretization.
% The approximation replaces the dominator of the last factor in Equation~\ref{eq:likelihood_one} with

% \begin{equation}
% {\frac{{\gamma_i}!}{ {n^{(P)}_{i,1} !} {n^{(P)}_{i,2} !} \cdots {n^{(P)}_{i,J_P} !}}} \approx \prod_{r=1}^{n_p} { {{{\gamma}_i}!}\over{ {n^{(P_r)}_{i,1} !} {n^{(P_r)}_{i,2} !} \cdots {n^{(P_r)}_{i,J_{P_r}} !}}}\text{,}
% \end{equation}

% \noindent
% where $P_r$ is the $r$th parent variable, $J_{p_r} = \| P_r\|$, and ${n^{(P_r)}_{i,j} !}$ is the number of instances in the $i$th interval with the $j$th value of $P_r$. Note that $\gamma_i = \sum_j {n^{(P_r)}_{i,j}}$ for all $r$.
% The approximated objective function is

% \begin{small}
%   \begin{equation}
%   \label{eq:opt_prob_approx}
%   \begin{aligned}
%     & \sum_{i=1}^{k-1}
%      - \ln
%       \paren{
%         1 - \exp
%         \paren{
%           - L \cdot  \frac{
%                            \cx_{\lambda_i +1} - \cx_{\lambda_i}
%                          }{
%                            \cx_n - \cx_1
%                           }
%         }
%       }
%         + \sum_{i=1}^{k}
%         L \cdot \frac{\cx_{\lambda_{i}} - \cx_{\lambda_{i-1} + 1}}{\cx_n - \cx_1} \\
%     & \sum_{i=1}^{k} \brock{
%     \ln{{\gamma_i + J_P - 1}\choose{J_P - 1}}
%     +{ \ln \paren{
%           \frac{
%             {\gamma_i}!
%           }{ \sum_{r=1}^{n_p}
%             {n^{({P_r})}_{i,1}}! \; {n^{({P_r})}_{i,2}}! \; \cdots \; {n^{({P_r})}_{i,J_{P_r}}}!
%           }
%         }}
%     } \\
%     & \sum_{j=1}^{n_c} \sum_{i=1}^k \sum_{l=1}^{J^{(j)}_S} \brock{
%     { \ln
%             {{n^{(j)}_{i,l} + J_{C_j} - 1}\choose{J_{C_j}-1}}}
%       +
%       \ln \paren{ {
%             \frac{
%               {n^{(j)}_{i,l}}!
%             }{
%               {n^{(j)}_{i,1,l}!} \; {n^{(j)}_{i,2,l}!} \; \cdots \; {n^{(j)}_{i,J_{C_j},l}!}
%             }
%           }
%           } }
%   \end{aligned}
%   \end{equation}
% \end{small}

% The approximation reduces the runtime of Algorithm~\ref{alg:disc_one} to a polynomial, $\todo{\bigo\paren{ {v'_\text{max}} \cdot (n_c + n_p) \cdot n^2}}$.
% It will be shown in Section~\ref{sec:experiments} that the approximation is more sensitive to the distribution over other variables and is biased towards slightly higher interval counts.
% \tim{We need to have a more specific thing to say along the lines of `When does it fail?'}

% The approximated objective function, Equation~\ref{eq:opt_prob_approx}, provides intuition into how child and parent variables contribute to the objective function.
% For example, in the left graph of Figure~\ref{fig:example_networks}, the corresponding square brackets in the approximated objective function are

% \begin{small}
%   \begin{equation}
%   \begin{aligned}
%   \label{eq:example_approx}
%    \sum_{i=1}^k & \left\lbrace   \left[ \ln{{\gamma_{i} + J_{C_1} - 1}\choose{J_{C_1}-1}} + \ln \left(  {{{\gamma_i}!} \over { {n^{(1)}_{i,1,\emptyset} !} \cdots {n^{(1)}_{i,J_{C_1},\emptyset} !}} }  \right)  +  \right. \right.\\
%   & \left.  \ln{{\gamma_{i} + J_{C_2} - 1}\choose{J_{C_2}-1}} + \ln \left(  {{{n_i}!} \over { {n^{(2)}_{i,1,\emptyset} !} \cdots {n^{(2)}_{i,J_{C_1},\emptyset} !}} }  \right)  \right] + \\
%   &  \left. \left[  \ln {{\gamma_{i} + J_P - 1}\choose{J_P-1}} +  \ln \left( { {{{\gamma}_i}!}\over{ {n^{(P_1)}_{i,1} !}\cdots {n^{(P_1)}_{i,J_{P_1}} !}}} \right) +\ln \paren{{ {{{\gamma}_i}!}\over{ {n^{(P_2}_{i,1} !}\cdots {n^{(P_2)}_{i,J_{P_2}} !}}} } \right] \right\rbrace \text{.}
%   \end{aligned}
%   \end{equation}
% \end{small}

% In Equation~\ref{eq:example_approx}, each child carries two terms, as shown in the first set of square brackets, but the two parent variables only carry a total of three terms, as shown in the second set of square brackets.
% In this case the child variables have greater effect on the optimal discretization than the parent variables, even though the number of child and parent variables are the same.
% However, if $C_2$ has an additional parent $S_2$, as shown in the right graph of Figure~\ref{fig:example_networks}, the importances of $C_2$ will be reduced.
% This is due to the additional influence of $S_2$ on $C_2$.
% This phenomenon arrises because the Bayesian method, but with and without the heuristic, incorporates graph structure when discretizing continuous variables.

% \begin{figure}[ht]
%   \centering
%   \begin{tabular}{cc}
%     \input{graph2_left}
%     \end{tabular}
%     \hspace{5em}
%     \begin{tabular}{cc}
%     \input{graph2_right}
%   \end{tabular}
%   \caption{Two example networks}
%   \label{fig:example_networks}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Multi-Variable Discretization}
\label{sec:multi_var}

\subsection{Discretization of Multiple Continuous Variables}

The single-variable discretization method can be extended to Bayesian networks with multiple continuous variables by iteratively discretizing individual variables.
The discretization process for a single variable requires that all other variables be discrete.
The iterative approach uses a prediscretization policy in order to initialize the process.
This work prediscretizes all continuous variables into $k$ equal-width intervals, where $k$ is largest value of the number of intervals of initially discrete variables in the network.

After prediscretization, the one-variable discretization method is iteratively applied over each continuous variable in reverse topoligical order, from the leaves to the root.
Reverse topological order has the advantage of relying on fewer prediscretizations of the continuous variables during the first pass.
For example, in the network of Figure~\ref{fig:example_networks}, if $S_2$ is the only discrete variable, then the discretization of $P_1$ involves both $P_2$ and $X$, whereas the discretization of $C_1$ only involves $X$.

\begin{figure}[ht]
 \centering
     \input{graph2_right}
  \caption{An example network}
   \label{fig:example_networks}
\end{figure}

The algorithm is terminated when the number of discretization intervals and their associated edges converge for all variables, and a maximum number of complete passes is enforced to prevent infinite iterations when convergence does not occur.
The algorithm typically converges within a few passes when tested on real-world data.
In cases where it does not converge, usually observed when also learning structure, ten passes produce decent discretization results.

The pseudocode for the multi-variable discretization procedure is shown in Algorithm~\ref{alg:disc_two}.
It requires four inputs: $D$, a dataset of samples from the joint distribution; $G$, the fixed network structure; $\bm{\cX}$, the set of all continuous variables in reverse topological order, and $\maxpasses$, an upper bound on the number of complete passes.

\begin{algorithm}
  \caption{Discretization of multiple continuous variables}
  \label{alg:disc_two}
  \begin{algorithmic}[5]
  \Function{DiscretizeAll}{$D$, $G$, $\bm{\cX}$, $\maxpasses$}
    \State $\discset \leftarrow$ the discretization policies for each $\cX$ in $\bm{\cX}$
    \State $D^* \leftarrow $ the dataset $D$ discretized according to $\discset$
    \State $k \leftarrow \textsc{Max}\paren{\curly{ |X| \text{ s.t. } X \text{ does not have corresponding } \cX \text{ in } \bm{\cX} }}$
    \For {$\paren{\cX, X}$ such that $\cX \in \bm{\cX}$ and $X$ is the discretized version of $\cX$}
      \State $\Lambda_{\cX} \leftarrow$ equal-width discretization of $\cX$ with $k$ intervals
      \State $D^*_{X} \leftarrow \Lambda_{\cX} \paren{D_{\cX}}$
    \EndFor
    \State $n_\text{cycle} \leftarrow 0$
    \While {$\discset$ has not converged \textbf{and} $n_\text{cycle} \leq \maxpasses$}
      \State increment {$n_\text{cycle}$}
      \For {$\paren{\cX, X}$ such that $\cX \in \bm{\cX}$}
        \State {$D^*_X \leftarrow D_{\cX}$}
        \State {$\Lambda_{\cX} \leftarrow \textsc{DiscretizeOne}(D^*, G, \cX)$}
        \State {$D^*_X \leftarrow \Lambda_{\cX}\paren{D_{\cX}}$}
      \EndFor
    \EndWhile
    \State \Return $\discset$
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Combining Discretization with Structure Learning}

In many situations the network structure is not known in advance and must be learned from data.
Traditional Bayesian structure learning algorithms require discretized data, whereas the proposed discretization algorithm requires a known network structure.
This section combines the proposed discretization method with the K2 structure learning algorithm \citep{K2} in an interative fassion to simultaneously perform Bayesian structure learning and discretization of continuous variables.

The proposed algorithm alternates between K2 structure learning and discretization.
K2 is run on the discretized dataset corresponding to prediscretizations for all continuous variables.
The affected continuous variables are rediscretized every time an edge is added by K2.
The resulting discretization policies are used to update the discretized dataset, and the next step of the K2 algorithm is executed.
This cycle is repeated until the K2 algorithm reaches a local maximum.

This procedure is given in Algorithm~\ref{alg:structure_learn}.
It takes five inputs: $D$, a dataset of samples from the joint distribution; $\bm{\cX}$, the set of all continuous variables; $\texttt{order}$, a permutation of the variables in $D$; $\hat{n}_\text{parent}$, an upper bound on the number of parents per node; and $\maxpasses$, an upper bound on the number of complete passes.
The function $g$ in Algorithm~\ref{alg:structure_learn} computes a component of the Bayesian score (Equation~\ref{eq:BayesianScore}):

\begin{equation}
  \label{eq:B_Score_one}
  g\paren{X_i, \Pa_{X_i}} =  \sum_{j=1}^{q_i} \ln\paren{
    \frac{
      \Gamma\paren{\alpha_{ij}^{(0)}}
    }{
      \Gamma\paren{\alpha_{ij}^{(0)} + \beta_{ij}^{(0)}}
    }
  } + \sum_{k=1}^{r_i} \ln \paren{
    \frac{
      \Gamma\paren{\alpha_{ij}^{(k)} + \beta_{ij}^{(k)}}
    }{
      \Gamma\paren{\alpha_{ij}^{(k)}}
    }
  }\text{.}
\end{equation}

\begin{algorithm}
  \caption{Learning a discrete-valued Bayesian network}
  \label{alg:structure_learn}
  \begin{algorithmic}[5]
  \Function{Learn\_DVBN}{$D$, $\bm{\cX}$, $\texttt{order}$, $\hat{n}_\text{parent}$, $\maxpasses$}
    \State $N \leftarrow$ the number of variables in the Bayesian network
    \State $k \leftarrow \textsc{Max} \{ \|v\|, v\notin C\}$
    \State $\discset \leftarrow$ the discretization policies for each $\cX$ in $\bm{\cX}$
    \State $D^* \leftarrow $ the dataset $D$ discretized according to $\discset$
    \State $G \leftarrow$ the initial edgeless graph structure
	\For {$\paren{\cX, X}$ such that $\cX \in \bm{\cX}$ and $X$ is the discretized version of $\cX$}
      \State $\Lambda_{\cX} \leftarrow$ equal-width discretization of $\cX$ with $k$ intervals
      \State $D^*_{X} \leftarrow \Lambda_{\cX} \paren{D_{\cX}}$
    \EndFor
    \For {$i \leftarrow 1$ to $N$}
      \State $P_{old} \leftarrow g(X_i,\Pa_{X_i})$ as Equation~\ref{eq:B_Score_one}
      \State OKToProceed $\leftarrow$ \textbf{true}
      \While {OKToProceed \textbf{and} $\|\Pa_{X_i}\| < \hat{n}_\text{parent}$}
        \State $Y \leftarrow$ an element from the set $\texttt{order}[1:i] \backslash \Pa_X$
        \State $P_{new} \leftarrow g(X_i,\Pa_{X_i} \cup Y)$
        \If {$P_{new} > P_{old}$}
          \State $P_{old} \leftarrow P_{new}$
          \State $\Pa_{X_i} \leftarrow \Pa_{X_i} \cup Y $
          \State $\bm{\cX '} \leftarrow$ sorted $\bm{\cX}$ by a reverse topological order of current $G$
          \State $\Lambda \leftarrow$ \textsc{DiscretizeAll}({$D$, $G$, $\bm{\cX '}$, $\maxpasses$}): Algorithm~\ref{alg:disc_two}
          \State $D^* \leftarrow \Lambda \paren{D_{\bm{\cX }}}$
        \Else
          \State OKToProceed $\leftarrow$ \textbf{false}
        \EndIf
      \EndWhile
    \EndFor
    \State \Return $G$, $\Lambda$
  \EndFunction
  \end{algorithmic}
\end{algorithm}

It is common practice to run K2 multiple times with different variable permutations and to then choose the structure with the highest score.
As such, Algorithm~\ref{alg:structure_learn} is run multiple times with different variable permutations and the discretized Bayesian network with the highest score is retaiend.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments}
\label{sec:experiments}

This section describes experiments conducted to evaluate the Bayesian discretization method.
All experiments were run on datasets from the publically available University of California, Irvine machine learning repository \citep{Lichman_2013}.
Variables are labeled alphabetically in the order given on the dataset information webpage.
In the figures that follow, shaded nodes correspond to initially discrete variables and the subscripts indicate the number of discrete instantiations.

Two experiments were conducted on each dataset.
The first experiment compares the performance of the Bayesian and MDL discretization methods on a known Bayesian network structure.
The structure was obtained by prediscretizing each continuous variable into $k$ uniform-width intervals, where $k$ is the median number of instantiations of the discrete variables, and using the structure with the highest Bayesian score from \num{1000} runs of the K2 algorithm with random variable orderings.
The second experiment compares the same methods applied when simultaneously discretizing and learning network structure.

The discretizations are compared using the mean cross validated log-likelihood of the data $D$ given the graph structure $G$ and discretization policies $\discset$.
Note that all log-likelihoods shown have been normalized by the number of data samples.
The log-likelihood has two components,

\begin{equation}
\ln p(D\mid G, \discset) = \ln P(D^*\mid G) + \ln p(D\mid \discset, D^*)\text{,}
\end{equation}

\noindent
where $D$ is the original dataset and $D^*$ is the dataset discretized according to $\discset$.
The log-likelihood of the discretized dataset is the Bayesian score (Equation~\ref{eq:BayesianScore}) evaluated with a uniform prior over graph structures and a uniform Dirichlet prior ($\alpha_{ijk} = 1$ for all $i$, $j$, and $k$).
The log-likelihood of the original dataset given the discrete dataset is

\begin{equation}
  \ln p\paren{D\mid \discset, D^*} = \sum_{i=1}^N
  1_{\curly{ \cX_i \in \bm{\cX }}}\cdot \sum_{k=1}^{r_i}  \sum_{j=1}^{q_i} \beta_{ij}^{(k)} \ln \paren{
    \frac{
      1
    }{
      e^{\Lambda_{\cX_i}}_{k} - e^{\Lambda_{\cX_i}}_{k-1}
    }
  }\text{.}
\end{equation}
Note that $e^{\Lambda_{\cX_i}}_{0} = \textsc{Min}\paren{D_{\cX_i}}$ and $e^{\Lambda_{\cX_i}}_{r_i} = \textsc{Max}\paren{D_{\cX_i}}$.
%, where $\brock{ e^{\Lambda_{\cX_i}}_{k-1} , e^{\Lambda_{\cX_i}}_{k} }$ is the discretization interval that $\cx_i$ falls in. If $\cx_i < e^{\Lambda_{\cX_i}}_{1}$, then the corresponding interval is $\brock{ \textsc{Min}\paren{D_{X_i}} , e^{\Lambda_{\cX_i}}_{1}}$. If $\cx_i \leq e^{\Lambda_{\cX_i}}_{r_i - 1}$, then the corresponding interval is $\brock{  e^{\Lambda_{\cX_i}}_{r_i - 1},\textsc{Max}\paren{D_{X_i}}}$.
\noindent
The mean cross-validated log-likelihood is the mean log-likelihood on the witheld dataset among cross-validation folds.
Cross-validation directly estimates generalization error.
Ten folds were used in each experiment.

The method for computing the MDL discretization policy is similar to the method for the Bayesian method.
For a Bayesian network with a single continuous variable $\cX$, the MDL objective function is

\begin{equation}
  \label{eqn:MDL}
  \begin{aligned}
  \frac{1}{2} \ln(n) \left\lbrace  \lvert \Pa_{\cX} \rvert (\lvert X \rvert - 1) +
   {\sum_{j,\cX \in \Pa_{X_j}}} \lvert \Pa_{X_j} \rvert (\lvert X_j \rvert - 1) \right\rbrace + \ln(|X|) \\
   + (m-1) H \paren{\frac{|X| - 1}{m -1}} -n \cdot \left[ I(X,\Pa_{\cX}) + {\sum_{j,\cX \in \Pa_{X_j}}} I(X_j, \Pa_{X_j}) \right]\text{,}
  \end{aligned}
\end{equation}
where $I(A,B)$ is the mutual information between two discrete variable sets $A$ and $B$, ${H(p) = -p \ln(p) - (1-p) \ln(1-p)}$, and $X$ is the discretized version of $\cX$. The minimum of Equation \ref{eqn:MDL} can be found by dynamical programming. It takes runtime $\bigo \paren{ n^3 + \paren{ n_c \cdot {L}^{n_s}  + {L}^{n_p}} \cdot n^2 }$, where the parameters are defined in Section \ref{subsec:algo}. Therefore, the runtime of the proposed method in this paper is shorter than MDL discretization method by $\bigo \paren{n^3}$.


\subsection{Auto MPG Dataset}
\label{subsec:auto}

The Auto MPG dataset contains variables related to the fuel consumption of automobiles in urban driving.
The dataset has \num{392} samples over eight variables, not including six instances with missing data.
Three variables are discrete: $B$, $G$, and $H$, with \num{5}, \num{13}, and \num{3} instantiations respectively.

\subsubsection{Discretization with fixed Structure}
\label{subsubsec:auto_exp1}

The Bayesian and MDL discretization methods were tested on the Auto MPG data using the network shown in Figure~\ref{fig:auto_graph_1}.
This structure was obtained by prediscretizing each continuous variable into five uniform-width intervals, where five is the median cardinality of the discrete variables, and then taking the structure with highest likelihood from \num{1000} runs of K2.

\begin{figure}[ht]
  \centering
   \input{graph_autocar_1}
   \caption{Bayesian network structure obtained from running K2 on the prediscretized Auto MPG dataset}
  \label{fig:auto_graph_1}
\end{figure}

Table~\ref{table:auto_disc_table_1} lists the discretization edges and mean log-likelihoods under \num{10}-fold cross validation of the discrete Bayesian network resulting from two discretization methods.
The MDL method does not produce any discretization edges, assigning one continuous interval to each continuous variable, and produces the result with the lower likelihood.
The cause of low number of discretization edges behind the MDL method is discussed in Section~\ref{subsec:discuss_exp}. On the other hand, there is a network structure where the MDL has a comparable result with the Bayesian method. Please refer to Appendix.

\begin{table}[h]
  \centering
  \caption{
    Results from discretization of the Auto MPG dataset with fixed structure from Figure~\ref{fig:auto_graph_1}.
    The first five rows list the discretization edges for each continuous variable.
    The last row lists the mean cross-validated log-likelihood; positive values are better.
    The MDL method does not produce any discretization edges.
  }
  \input{table_autoMPG_1.tex}
  \label{table:auto_disc_table_1}
\end{table}

Figure~\ref{fig:auto_exp1_distr_1_3} shows the marginal probability density for variables $A$ and $C$ under the Bayesian discretization policy overlaid with the original Auto MPG data.
The resulting probability density is a good match to the original data.

\begin{figure}[ht]
  \centering
  \input{graph_auto_exp1_distr_1_3}
  \caption{
    Comparison of the Bayesian discretization policy for variables $A$ and $C$ to the original Auto MPG data learned with a fixed network.
    The marginal probability density closely matches the data.
  }
  \label{fig:auto_exp1_distr_1_3}
\end{figure}

%\subsubsection{Discretization while Learning Structure}
\label{subsubsec:auto_exp2}

In this experiment the network structure was not fixed in advance and was learned simultaneously with the discretization policies.
Figure~\ref{fig:auto_graph_2} shows a learned Bayesian network structure and the corresponding numbers of intervals after discretization for each continuous variable.
This result was obtained by running Algorithm~\ref{alg:structure_learn} fifty times using the Bayesian method and choosing the structure with the highest K2 score (Equation \ref{eq:BayesianScore}).

\begin{figure}[ht]
  \centering
  \input{graph_autocar_2}
  \caption{The discrete-valued Bayesian network learned from the Auto MPG dataset using the Bayesian method.}
  \label{fig:auto_graph_2}
\end{figure}

Figure~\ref{fig:auto_exp2_distr_1_3} compares the Bayesian discretizaton policy for variables $A$ and $C$ in the learned network with the original Auto MPG data.
The color of a discretized region indicates the marginal probability density of a sample from $P(A,C)$ being drawn from that region.
Although there are fewer discretization edges for $A$ and $C$ in the learned network, the marginal distribution is still captured.
The discretization policy will vary according as the network structure changes, and it still produces high-quality discretizations.

\begin{figure}[ht]
  \centering
  \input{graph_auto_exp2_distr_1_3}
  \caption{
    Comparison of the Bayesian discretization policy for variables $A$ and $C$ to the original Auto MPG data learned simultaneously with the network structure.
    Although the number of discretization edges is less than those in Figure~\ref{fig:auto_exp1_distr_1_3}, the probability distribution still closely matches the original data.
  }
  \label{fig:auto_exp2_distr_1_3}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% WINE
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Dataset 2: Wine}
\label{subsec:wine}

The Wine dataset contains variables related to the chemical analysis of wines from three different Italian cultivars.
The dataset has \num{178} samples over fourteen variables.
Variable $A$ is the only discrete variable and has three instantiations.

\subsubsection{Discretization with fixed Structure}
\label{subsubsec:wine_exp1}

The Bayesian and MDL discretization methods were tested on the Wine data using the network shown in Figure~\ref{fig:wine_graph_1}.
This structure was obtained by prediscretizing each continuous variable into three uniform-width intervals, where three is the median cardinality of the discrete variables, and then taking the structure with highest likelihood from \num{1000} runs of K2.

Table~\ref{table:wine_disc_table_1} lists the discretization edges and mean log-likelihoods under \num{10}-fold cross validation of the Bayesian network resulting from each discretization method.
The Bayesian method outperforms the MDL method in likelihood by a significant margin.
The MDL method creates significantly fewer discretization edges.
% The heuristic method discretizes the variables $G$, $H$, and $J$ into one fewer interval and the variable $M$ into one more interval than the optimal Bayesian approach, resulting in a slightly lower mean cross validated log likelihood.
% The overall performance of the heuristic method is still very high, and if runtime is the primary concern, the heuristic method can be considered the better approach.
% \tim{Do we need to list runtime too?}

Some discretization edges appear in all three discretization methods, such as \num{1.42} and \num{2.35} for variable $C$ and \num{0.785} for variable $L$.
This indicates that MDL indeed can find some important discretization edges, but it is not sensitive enough to find more edges.

\begin{figure}[ht]
  \centering
  \scalebox{0.8}{\input{graph_wine_1}}
  \caption{Bayesian network structure obtained from running K2 on the prediscretized Wine dataset}
  \label{fig:wine_graph_1}
\end{figure}

\begin{table}
  \centering
  \caption{
    Results from discretization of the Wine MPG dataset with fixed structure.
    % The first thirteen rows list the discretization edges for each continuous variable.
    % The last row lists the mean cross-validated log-likelihood; positive values are better.
    % The optimal Bayesian approach has the best discretization result in terms of likelihood, but the heuristic method obtains a similar result with nearly the same likelihood.
    % The MDL method produces discretization edges for more than half of the continuous variables but does not produce enough discretization intervals.
    % Some discretization edges appear in the results of all three methods.
    Bold discretization edges were identified by both methods.
  }
  \scalebox{1.0}{
  \input{table_wine_1.tex}
  }
  \label{table:wine_disc_table_1}
\end{table}

Figure~\ref{fig:wine_exp1_distr} compares the Bayesian and MDL discretizaton policies for variables $E$ and $K$ with the original Wine data.
The discretization edges \num{17.9} for $E$ and \num{34.6} for $K$ appear in both plots.
The MDL method does not use enough intervals for discretization.
Relative sensitivities of each method to the input data is discussed in Section~\ref{subsec:discuss_exp}.

\begin{figure}[ht]
  \centering
  \input{graph_wine_exp1_distr}
  \caption{Comparison of the discretization policies for variables $A$ and $C$ obtained using the Bayesian and MDL methods}
  \label{fig:wine_exp1_distr}
\end{figure}

\subsubsection{Discretization while Learning Structure}
\label{subsubsec:wine_exp2}

Figure~\ref{fig:wine_graph_2} is the discrete-valued Bayesian network learned from the Wine dataset, obtained by running Algorithm~\ref{alg:structure_learn} fifty times.
A comparison of Figures~\ref{fig:wine_graph_2} and \ref{fig:wine_graph_1} show that the Bayesian network learned during the discretization process has more edges than the network learned on the prediscretized data.
When a network is learned along with discretization, the algorithm has more freedom to adjust the structure and the discretization policy simultaneously to identify useful correlations and produce a denser structure.

Figure~\ref{fig:wine_exp2_distr} shows the discretization policy for variables $E$ and $K$ obtained with the Bayesian method.
The discretization edge also $E = 17.9$ appears in both discretization policies from the fixed network (Figure~\ref{fig:wine_exp1_distr}).
This suggests that discretization edges can be robust against network structure.
Furthermore, the discretization edge at $E = 23.5$ present in the fixed-structure case is missing in the learned structure.
This is caused by $E$ having twice as many parents in the learned network structure.
The more parents a variable has, the less discretization intervals it can to support, as the set of statistics required to define the resulting distribution increases exponentially with the number of parents.

\begin{figure}[ht]
  \centering
  \scalebox{0.7}{\input{graph_wine_2}}
  \caption{The discrete-valued Bayesian network learned from the Wine dataset using the Bayesian method.}
  \label{fig:wine_graph_2}
\end{figure}

\begin{figure}[ht]
  \centering
  \input{graph_wine_exp2_distr_5_11}
  \caption{
    The discretization policy for variables $E$ and $K$ on the learned network.
    The discretization edge $E = 17.9$ also appears in the policies for the fixed network.
  }
  \label{fig:wine_exp2_distr}
\end{figure}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Housing
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Data 3: Housing}
\label{subsec:housing}

The Housing dataset contains variables related to the values of houses in Boston suburbs.
The dataset has \num{506} samples over fourteen variables.
Only variables $D$ and $I$ are discrete-valued, with \num{2} and \num{9} instantiations, respectively.
Despite their being continuous, several variables in the Housing dataset possess many repeated values.
The following experiments were conducted with a maximum of three parents per variable to prevent running out of memory when running MDL.

\subsubsection{Discretization with Fixed Structure}
\label{subsubsec:housing_exp1}

The Bayesian network structure in Figure~\ref{fig:housing_graph_1} was obtained by prediscretizing each continuous variable into five uniform-width intervals and then running the K2 algorithm \num{1000} times and choosing the network with the highest likelihood.
Table~\ref{table:housing_disc_table_1} shows the numbers of intervals after discretization for each continuous variables and the log-likelihood of the dataset based on each discretization method.
MDL method does not produce any discretization edges for most variables.
% The heuristic Bayesian method produces far more discretization edges than the Bayesian method due to repeated instances in the dataset.
% The numbers of intervals returned by the each method illustrate the over-sensitive nature of the heuristic method and the under-sensitive nature of the MDL method.
% \tim{I am not sure we are using `sensitive' correctly. Sensitive to what? Perhaps `biased towards higher edge counts'?}
The relative weighting of each method's objective function will be discussed in Section~\ref{subsec:discuss_exp}.

% The heurstic method produces the discretization with the highest cross-validated log-likelihood; and although the heuristic method leads to a higher number of intervals, its likelihood is not significantly better than the Bayesian approach.
% This demonstrates that the Bayesian approach captures the most important discretization edges.

\begin{figure}[ht]
  \centering
  \scalebox{0.8}{\input{graph_housing_1}}
  \caption{Bayesian network structure obtained from running K2 on the prediscretized Housing dataset}
  \label{fig:housing_graph_1}
\end{figure}

\begin{table}
  \centering
  \caption{
    Discretization policy summary of the Housing dataset based on the fixed network structure shown.
    The first twelve rows show the numbers of intervals after discretization for each method.
    The last row is the mean cross-validated log-likelihood based on each discretization result.
    % The heuristic method is over-sensitive \todo{to what?} and discretizes some variables into too many intervals.
    % The MDL method is less sensitive and on many cases does not produce any discretization intervals.
    % The optimal Bayesian approach produces a reasonable number of discretization edges.
  }
  \input{table_housing_1.tex}
  \label{table:housing_disc_table_1}
\end{table}

Figures~\ref{fig:housing_exp1_distr_3_5} and \ref{fig:housing_exp1_distr_8_5} show the discretization policy learned using the Bayesian approach on the fixed network shown in Figure~\ref{fig:housing_graph_1}.
The scatter points in Figure~\ref{fig:housing_exp1_distr_3_5} were jittered to show the quantity of repeated values for variables $C$ and $E$.
Each repeated point forms a single discrete region, thereby encouraging discretization.
In contrast, the samples for $H$ are well spread out, resulting in fewer discretization regions and larger discretization intervals.

\begin{figure}[ht]
  \centering
  \input{graph_housing_exp1_distr_3_5}
  \caption{
    The discretization policies for variables $C$ and $E$ learned using the Bayesian approach on the fixed network.
    The scatter points were jittered to reveal the repeated values in the dataset.
    The repeated values lead to a high number of discretization edges, because repeated values can easily form discretized regions by their own.
  }
  \label{fig:housing_exp1_distr_3_5}
\end{figure}

\begin{figure}[ht]
  \centering
  \input{graph_housing_exp1_distr_8_5}
  \caption{
    The discretization policies for variables $H$ and $E$ learned using the optimal Bayesian approach on the fixed network shown in Figure~\ref{fig:housing_graph_1}.
    The variable $H$ possesses no overly repeated values, thus producing a cleaner discretization policy.
  }
  \label{fig:housing_exp1_distr_8_5}
\end{figure}

\subsubsection{Discretization while Learning Structure}
\label{subsubsec:housing_exp2}

Figure~\ref{fig:housing_graph_2} shows a learned Bayesian network structure and the corresponding numbers of intervals after discretization for each continuous variable.
Variable $D$ is neighborless in both the learned and fixed networks.
The continuous variables $C$, $E$, $J$ and $K$, which are all connected through $C$, have many discretization intervals.
Typically, when discretizing a variable, the expected number of discretization intervals is close to the highest cardinality among variables in its Markov blanket.
This naturally leads to clusters of variables with many discretization intervals.

\begin{figure}[ht]
  \centering
  \scalebox{0.8}{\input{graph_housing_2}}
  \caption{
    The discrete-valued Bayesian network learned from the Housing dataset using the optimal Bayesian method.
  }
  \label{fig:housing_graph_2}
\end{figure}

Figure~\ref{fig:housing_exp2_distr_3_5} and Figure~\ref{fig:housing_exp2_distr_8_5} show the discretization result on variables of the network in Figure~\ref{fig:housing_graph_2}.
Again, variable $C$ and $E$ have many discretization edges due to the repeated values.
Although the number of intervals after discretization on $H$ is less the number in Figure~\ref{fig:housing_exp1_distr_8_5}, it still captures the distribution of the raw data along with the discretization edges on $E$.

\begin{figure}[ht]
  \centering
  \input{graph_housing_exp2_distr_3_5}
  \caption{
    The discretization policy for variables $C$ and $E$ on the learned network in Figure~\ref{fig:housing_graph_2}.
    The high number of discretization edges are caused by repeated values in $C$ and $E$.
  }
  \label{fig:housing_exp2_distr_3_5}
\end{figure}

\begin{figure}[ht]
  \centering
  \input{graph_housing_exp2_distr_8_5}
  \caption{
    The discretization policy for variables $H$ and $E$ on the learned network in Figure~\ref{fig:housing_graph_2}.
    The number of discretization intervals for $H$ is less than it was for the fixed network structure in Figure~\ref{fig:housing_exp1_distr_8_5}, but the discretization policy still matches the raw data.
  }
  \label{fig:housing_exp2_distr_8_5}
\end{figure}

\subsection{Discussion}
\label{subsec:discuss_exp}

\begin{figure}[ht]
  \centering
  \input{graph_exp_discuss}
  \caption{A simple Bayesian network used to demonstrate the sensitivity of each method}
  \label{fig:exp_discuss}
\end{figure}

To quantatively discuss the sensitivity of each methods to the number of discretization intervals, consider the Bayesian network in Figure~\ref{fig:exp_discuss}, where $\cX$ is continuous and $P_1$ and $P_2$ are discrete.
If $\Pa_{\cX} = \curly{P_1, P_2}$ and $D_{\cX} = \curly{1.0,2.0,3.0, \ldots n}$, then the corresponding objective functions for the discretization methods are:

\begin{small}
  \begin{equation}
  \begin{aligned}
  f_{\text{MDL}} & = \overbrace{Z_1 \cdot k + \ln(k) + \ln {{n +k - 1}\choose{k -1}} }^{\text{Penalty Term}}+   \overbrace{\rule{0pt}{1.35em} \ln(N) \cdot I(X^*, \Pa_X)}^{\text{Edge Position Term}} \\
  f_{\text{Bayesian}} &= \underbrace{{\vrule width0pt height0pt depth1.48em\relax}  Z_2 \cdot k + \sum_{i=1}^k \ln {{\gamma_i + J_P - 1}\choose{J_P -1}}}_{\text{Penalty Term}} + \underbrace{\sum^k_{i=1} \ln \left(   {{\gamma_i !}\over{n^{(P)}_{i,1}! n^{(P)}_{i,2}! \cdots n^{(P)}_{i,J_P}!    }} \right) }_{\text{Edge Position Term}}
  % f_{\text{Heuristic}} &= \overbrace{Z_2 \cdot k + \sum_{i=1}^k \ln {{\gamma_i + J_{P_1} - 1}\choose{J_{P_1} -1}} + \sum_{i=1}^k \ln {{\gamma_i + J_{P_2} - 1}\choose{J_{P_2} -1}} }^{\text{Penalty Term}}+\\
  % & \overbrace{\sum^k_{i=1}  \left[ \ln \left(   {{\gamma_i !}\over{n^{(P_1)}_{i,1}! n^{(P_1)}_{i,2}! \cdots n^{(P_1)}_{i,J_{P_1}}    }} \right)  + \ln \left(   {{\gamma_i !}\over{n^{(P_2)}_{i,1}! n^{(P_2)}_{i,2} \cdots n^{(P_2)}_{i,J_{P_2}} }} \right) \right]}^{\text{Edge Position Term}}
  \end{aligned}\text{,}
  \end{equation}
\end{small}

\noindent
where $Z_1$ and $Z_2$ are constant over discretizations, $k$ is the number of discretization intervals, and $I\paren{A, B} = \sum_{a,b} \hat{P}(a,b) \ln\frac{\hat{P}(a,b)}{\hat{P}(a)\hat{P}(b)}$ is the mutual information based on estimated probabilities.
Note that the third term of $f_\text{MDL}$ had been approximated using $H(p)$ (see Equation~\ref{eqn:MDL}) in the original work by \cite{Friedman_1996}, but here is written without that approximation.

The sensitivities of each method to the discretization edges are captured in the edge position terms, as the penalty terms are similar across methods.
The value of the edge position term for MDL is primarly determined by the mutual information, which varies less severely than the corresponding terms for the Bayesian methods.
The MDL term uses emperical probability distributions, based off of ratios of counts, whereas the Bayesian methods use factorial terms, and thus vary less severely.
The MDL method is therefore less sensitive to the discretization edges.
This sensitivity gives rise to the relative performance of the two methods in the experiments conducted above.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
This paper introduced a principled discretization method for continuous variables in Bayesian networks with quadratic complexity instead of the cubic complexity of other standard techniques.
Emperical demonstrations show that the proposed method is superior to the state of the art.
In addition, this paper shows how to incorporate existing methods into the structure learning process to discretize all continuous variables and simultaneously learn Bayesian network structures.
The proposed method was incorporated and its superior performance was empirically demonstrated.
\todo{All software is publically available to support discretization research.}

The methods developed in this paper increase the accuracy of Bayesian networks learned on datasets with continuous and mixed variables.
An automated process for simultaneously constructing Bayesian networks and discretization policies is appearing because of the potential to significantly reduce development time and cost.
Future work will investigate edge positions at locations other than the midpoints between samples and using different discretization policies for the same variable in different conditional probablity distributions.

%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
%\begin{thebibliography}{}
\bibliographystyle{spbasic}
\bibliography{my_bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Appendix}
\label{sec:appendix}

The Bayesian network structure in Figure \ref{fig:auto_graph_3} and the discretization results in Table \ref{table:auto_disc_table_3} demonstrate that the MDL method does not always return smaller number of discretization intervals than the Bayesian approach and also the MDL method can return a comparable result in terms of likelihood. The Bayesian network in Figure \ref{fig:auto_graph_3} is obtained by running Algorithm \ref{alg:structure_learn} fifty times with $u_{\text{parent}} = 2$. Therefore, this network can be considered more well-structured than the one in Figure \ref{fig:auto_graph_1}, since the effect of discretization policies has already been considered in the learning process.
Many edges appears in both discretization results, as the bold numbers in Table \ref{table:auto_disc_table_3}. 
\begin{figure}[ht]
  \centering
  \scalebox{0.8}{
   \input{graph_autocar_3}}
   \caption{A Bayesian network structure for Auto MPG dataset that leads to a comparable discretization result of the MDL method with the Bayesian method}
  \label{fig:auto_graph_3}
\end{figure}

\begin{table}[h]
  \centering
  \caption{
    Results from discretization of the Auto MPG dataset with fixed structure from Figure~\ref{fig:auto_graph_3}.
    The first five rows list the discretization edges for each continuous variable.
    The last row lists the mean cross-validated log-likelihood.
    Two methods have same discretization result on variable $A$.
    Log-likelihood shows that the MDL method is just slightly worse than the Bayesian method.
  }
\input{table_autoMPG_3.tex}
  \label{table:auto_disc_table_3}
\end{table}
\end{document}
% end of file template.tex

