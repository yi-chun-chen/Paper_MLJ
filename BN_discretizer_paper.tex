%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{amsmath}
\usepackage{bm}
\usepackage{graphicx} % Allows including images
\usepackage{epstopdf}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[round]{natbib}
\usepackage{amsfonts} % for mathbb
\usepackage{tikz}
% \usepackage[capitalize]{cleveref}
\usetikzlibrary{bayesnet}
\setcitestyle{aysep={ }} %Author-Year Separator
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CUSTOM COMMANDS

\newcommand{\bigo}{\mathcal{O}} % NOTE(tim): if you prefer normal O change it here.

\newcommand{\paren}[1]{\mathopen{}\mathclose\bgroup\left(#1\aftergroup\egroup\right)}
\newcommand{\brock}[1]{\mathopen{}\mathclose\bgroup\left[#1\aftergroup\egroup\right]}
\newcommand{\curly}[1]{\mathopen{}\mathclose\bgroup\left\{#1\aftergroup\egroup\right\}}
\newcommand{\anglebrackets}[1]{\langle #1 \rangle}
\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\todo}[1]{\textcolor{magenta}{#1}}
\newcommand{\tim}[1]{\textit{\textcolor{blue}{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Learning Discrete-valued Bayesian Networks from Mixed Data%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Yi-Chun Chen           \and
        Tim A. Wheeler         \and
        Mykel J. Kochenderfer
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{F. Author \at
              first address \\
              Tel.: +123-45-678910\\
              Fax: +123-45-678910\\
              \email{fauthor@example.com}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           S. Author \at
              second address
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
\todo{
Insert your abstract here. Include keywords, PACS and mathematical
subject classification numbers as needed.
}
\keywords{Discretization \and Bayesian Network \and Continuous Variable}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{intro}
Bayesian networks \citep{Pearl_1988, PGM_2009} are an increasingly popular method for modeling uncertainty and causality in science and engineering. They provide an efficient factorization of the joint probability distribution over a set of random variables. Bayesian networks first emerged from artificial intelligence research and have been applied to a wide variety of problems, ranging from decision-making systems \citep{DMU_2015} to medical diagnoses \citep{Lustgarten_2011}. In most cases, we assume that all random variables in Bayesian networks are discrete, since many Bayesian network learning algorithms are unable to deal with continuous variables efficiently. However, many applications
require the use of continuous variables, such as position and velocity in dynamic systems.

There are two common approaches to extending Bayesian networks to continuous variables.
The first is to model the conditional probability density of each continuous variable using specific families of parametric distributions, and then to redesign Bayesian network learning algorithms based on their parameters.
One successful example is belief propagation in Gaussian graphical models \citep{Weiss_2011}.
For other parametric distributions \citep{Ihler_2009} and non-linear functions~\todo{[cite]}, these redesigned algorithms are computationally expensive and do not perform well.

The second approach is discretization.
Automated discretization methods have been studied in machine learning and statistics for many years \citep{Dougherty_1995, Kerber_1992, Holte_1993, Fayyad_1993}, primarily for classification problems.
They search for the best discretization policy of a continuous attribute by considering its interation with the target class variable.
Interations and dependencies between variables in Bayesian networks are more complicated, where discretization requires considering the impact on the variable's Markov blanket.
Prior work exists for discretizing continuous variables in naive Bayesian networks and tree-augmented networks \citep{Fried_naive}, but only a few discretization methods for general Bayesian networks have been proposed \citep{Friedman_1996, Kozlov_1997, Monti_1998, Steck_2007}.

This paper describes a new Bayesian discretization method for continuous variables in Bayesian networks, extending prior work on single-variable discretization methods from \citet{Boulle_2006} and \citet{Lustgarten_2011}.
The proposed method optimizes the discretization policy relative to the network and takes parents, children, and spouse variables into account.
The optimal single-variable discretization method is derived in Section \ref{sec:single_var}, and a second heuristic method is proposed which reduces the runtime from exponential to polynomial.
Section \ref{sec:multi_var} covers Bayesian networks with multiple continuous variables and discretization while simultaneously learning network structure.
The paper concludes with a comparison against the existing minimum-description length \citep{Friedman_1996} method on real-world datasets in Section \ref{sec:experiments}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{sec:related_work}
This section reviews the minimum description length (MDL) principle discretization \citep{Friedman_1996} and MODL discretization \citep{Boulle_2006} methods.
The former is the predominant discretization method for continuous variables in Bayesian networks, and is compared to our proposed method in Section \ref{sec:experiments}.
The latter is a discretization method for one continuous variable against a discrete target class, which our proposed method generalizes to Bayesian networks.
The asymptotical equivalence between MDL and MODL was examined in \citep{VL_2000}.

\subsection{MDL Principle Discretization}
The MDL principle was first proposed by \cite{MDL_1978}, and states that the best model for a dataset is one which minimizes the amount of information needed to describe it \citep{Grunwald_2009}.
MDL methods trade off goodness-of-fit against model complexity to reduce generalization error.
In the context of Bayesian networks, \cite{Friedman_1996} applied the MDL principle to determine the optimal number of discretization intervals for continuous variables and optimal the positions of their discretization boundaries.
Their approach selects a discretization policy that minimizes the sum of the description lengths of the discretized Bayesian network and the information necessary for recovering the continuous values from the discretized data.
In the single continuous variable case, the objective function is

% \begin{small}
\begin{equation}
\begin{aligned}
\frac{1}{2} \log(N) \left\lbrace  \lvert \Pi_{X_i} \rvert (\lvert X^*_i \rvert - 1) +
 {\sum_{j,X_i \in \Pi_{X_i}}} \lvert \Pi_{X^*_j} \rvert (\lvert X_j \rvert - 1) \right\rbrace + \log(\lvert {X^*_i} \rvert) \\
 + (N_i-1) H \left( {{|X^*_i| - 1}\over{N_i -1}}  \right) -N \cdot \left[ I(X^*_i,\Pi_{X_i}) + {\sum_{j,X_i \in \Pi_{X_i}}} I(X_j, \Pi_{X^*_j}) \right],
\end{aligned}
\end{equation}
% \end{small}

\noindent
% $I(\boldsymbol{A},\boldsymbol{B}) =  \sum_{\boldsymbol{a},\boldsymbol{b}} \hat{P}_D (\boldsymbol{a},\boldsymbol{b}) \log {{\hat{P}_D (\boldsymbol{a},\boldsymbol{b})}\over{\hat{P}_D (\boldsymbol{a}),\hat{P}_D (\boldsymbol{b})}}$
where $I(\boldsymbol{A},\boldsymbol{B})$ is the mutual information between the discrete variables $\boldsymbol{A}$ and $\boldsymbol{B}$, ${H(p) = -p \log(p) - (1-p) \log(1-p)}$, $|\boldsymbol{X}|$ is the cardinality of discrete variable $\boldsymbol{X}$, and $X^*_i$ is the discretized version of the $i$th sample of continuous variable $X$.
The optimal discretization policy can be found with dynamical programming.
For Bayesian networks with multiple continuous variables, the algorithm is applied to one variable at a time iteratively over all continuous variables.
While iterating, only one variable is treated as continuous and other continuous variables are discretized based on an initial discretization policy or the discretization result from a previous iteration.

The network structure is not always known in advance. Bayesian network structure learning can be extended to distributions including continuous variables by alternating between traditional discrete structure learning and optimal discretization. Starting with some preliminary discretization policy, one applys a structure learning algorithm to identify the locally optimal graph structure. The discretization policy is refined based on the learned network. The cycle is continued until convergence.

% The discretization technique proposed by \citet{Friedman_1996} is the most well-known of these methods. It is based on the minimum description length principle (MDL): the optimal discretization policy minimizes the description length of the Bayesian network and discretization policy. The MDL algorithm has a $\bigo\paren{N^3 + \paren{n_c {v_\text{max}}^{(n_c^p)_\text{max}} + {v_\text{max}}^{n_p}} \cdot N^2}$ runtime on Bayesian networks with a single continuous variable and multiple discrete variables, where $N$ is the number of data samples from the joint distribution, $n_p$ and $n_c$ are the numbers of parent and children variables for the continuous variable, $v_\text{max}$ is the largest cardinality over all variables in the Markov blanket, and  ${(n_c^p)_\text{max}}$ is the largest number of parent variables of the continuous variable's children. The MDL method iterates over all continuous variables until convergence in the case of multiple continuous variables, converging in a few cycles according to our tests of real-world data. Unfortunately, MDL tends to produce discrete variables with low cardinality~\todo{[cite]}.

\subsection{MODL Discretization}
MODL discretization \citep{Boulle_2006} is a Bayesian method for discretizing a continuous feature according to a class variable. Bayesian methods maximize the probability of the model given the data, $P(\textit{Model} \mid \textit{Data})$. An application of Bayes' rule and constant $P(\textit{Data})$ shows that this is equivalent to maximizing:
\begin{align}
P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model})\text{,}
\end{align}

\noindent
where $P(\textit{Model})$ is a prior over models and ${P(\textit{Data} \mid \textit{Model})}$ is the data likelihood.
The data likelihood usually increases with the number of discretization intervals, as more intervals allow for richer representations.
The prior decreases as the number of discretization intervals increases to favor simpler models and prevent overfitting.
Maximizing ${P(\textit{Model}) \cdot P(\textit{Data} \mid \textit{Model})}$ requires a trade-off when determining the number of discretization intervals.

The MODL method uses dynamic programming to find the optimal discretization policy, and has a $\bigo\paren{N^3 + |\text{Class}| \cdot N^2}$ runtime, where $N$ is the of number of data instances.
\cite{Lustgarten_2011} suggest several formulations for the prior term $P(\text{Model})$.
Under a uniform prior probability over discretizations the runtime can be reduced to $\bigo\paren{|\text{Class}| \cdot N^2}$ without sacrificing optimality.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}
\label{sec:preliminaries}
This section provides a brief overview of Bayesian networks, including the factorization of joint probability distributions, sampling from a Bayesian network, and structure learning. These concepts will be used in later sections. The formal definition of a discretization policy for a continuous variable is also given.

\subsection{Bayesian Networks and Structure Learning}

A Bayesian network $B$ is defined by a pair $(G,\Theta)$, where $G = (X,E)$ is a directed acyclic graph whose nodes correspond to a set of random variables $X = \brock{X_1, X_2, \cdots, X_n}$, and whose edges $E$ represent probabilistic dependencies among nodes. The graph structure $G$ encodes the Markov property: each node $X_i$ is independent of its non-descendants given its parents $\Pi_{X_i}$ in $G$. The conditional relations are parameterized by the elements of $\Theta$, which take the form $\theta_{x_i \mid \Pi_{x_i}} = P(x_i \mid \Pi_{x_i})$ for each possible value $x_i$ of $X_i$, and $\Pi_{x_i}$ of $\Pi_{X_i}$. The joint distribution over $X$ factors according to the Markov property:
\begin{equation}
P_B (X_1 , \cdots, X_n) = \prod_{i=1}^{n} P_B (X_i \mid \Pi_{X_i}) = \prod_{i=1}^{n} \theta_{x_i \mid \Pi_{x_i}}\text{.}
\end{equation}

Forward sampling is used to draw samples from the joint distribution represented by a Bayesian network.
Variables are sampled in topological order such that parental instantiations are always known~\citep[see][chap.~22]{algo_2009}.
Furthermore, the parent\rightarrow child sampling order can be reversed if the marginal probability of the child variable is known.
By Bayes' rule,

\begin{equation}
P(X_i \mid \Pi_{X_i}) \cdot \prod_{j = 1}^{ Pa( X_i)} P( \{ \Pi_{X_i} \}_j) = P(X_i) \cdot P(\Pi_{X_i} \mid X_i),
\end{equation}

\noindent
where $Pa(X_i)$ is the number of parents of $X_i$ and $\brock{\Pi_{X_i}}_j$ is the $j$th parent of $X_i$.
% One can first sample $X_i$ by $P(X_i)$, then sample all the parent variables simultaneously by $P(\Pi_{X_i} \mid X_i)$. That is to say, $X_i$ becomes the starting point of sampling.

It is often necessary to infer the structure of a Bayesian network from data.
Three common approaches to Bayesian network structure learning are constraint-based, score-based, and Bayesian model averaging \citep[see][chap.~18]{PGM_2009}. This work uses the K2 structure learning algorithm \citep{K2}, one of the most successful score-based structure learning methods.
Score-based structure learning methods over discrete variables commonly evaluate candidate structures according to their likelihood, $\prod_i f(X_i, \Pi_{X_i})$, where

\begin{align}
f(X_i, \Pi_{X_i}) = \prod_{j=1}^{|\Pi_{X_i}|} {{(|X_i|-1)!}\over{(N_{ij} + |X_i|-1)!}} \prod_{k=1}^{|X_i|} \alpha_{ijk}!\text{,}
\end{align}

\noindent
where $|X_i|$ is the cardinality of $X_i$, $|\Pi_{X_i}|$ is number of possible instantiations of the parent variables of $X_i$, $\alpha_{ijk}$ is the number of instances of the $k$th value of $X_i$ with the $j$th parental instantiation, and $N_{ij} = \sum_{k=1}^{|X_i|} \alpha_{ijk}$.
The optimal structure is the most probably structure given the data.
The space of acyclic graphcs is superexponential in the number of nodes so it is common to rely on heuristic search strategies \citep{PGM_2009}.

The K2 algorithm assumes a topological ordering of variables and greedily adds parents to nodes to maximally increase the likelihood score.
A fixed ordering ensures acyclicity but does not guarantee a globally optimal network structure.
K2 is typically run multiple times with random variable orderings and the network with the highest likelihood is retained.

\subsection{Discretization Policies}

A discretization policy $M_C = \anglebrackets{t_1 < t_2 < \ldots < t_{k-1}}$ for a continuous variable $C$ is a mapping from $\mathbb{R}$ to $\brock{1,2,3,\ldots,k}$ such that
\begin{equation}
  M_C (x)=\begin{cases}
    1, & \text{if $x<t_1$}.\\
    i, & \text{if $t_{i-1} \leq x < t_i$}\text{.}\\
    k, & \text{if $t_{k-1} \leq x$}
  \end{cases}
\end{equation}

\noindent
The policy discretizes the continuous variable $C$ into $k$ intervals.
The discretization edges $t_\cdot$ are restricted to the midpoints between two sorted instances of $C$.
An integer representation of $M_C$ can be obtained by sorting the samples of $C$ in an increasing order, $\curly{c_1,c_2,\ldots,c_N}$, and if $t_i = (c_{s_{i}} + c_{s_{i}+1})/2$ for $i=1,2,\ldots,k$, then $M_C = \anglebrackets{t_1,t_2, \ldots, t_{k-1}} \equiv \brock{n_1,n_2,..n_k}$, where $n_1 = s_1$ and $n_i = s_{i} - s_{i-1}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discretization of a Single Continuous Variable}
\label{sec:single_var}

This section covers discretization of a single continuous variable $X$ in a Bayesian network where all other variables are discrete.
Let $n_p$ and $n_c$ respectively refer to the number of parents and number of children of $X$.
Each child $C_i$ of $X$ may possess other parents, referred to as spouses of $X$.
The set of spouses of $X$ is denoted $\boldsymbol{S_i}$.

Let $D$ be a dataset of $N$ samples from which the discretization will be learned, sorted in ascending order according to $X$.
Let $D_{\boldsymbol{Y}}$ will refer to the data instances associated with variables $\boldsymbol{Y}$, thus $D_X = \{ x_1,x_2,x_3,\ldots,x_N \}$.
In order to facilitate understanding, we temporarily assume all values in $D_X$ are unique, that is, $x_1 < x_2 < \ldots < x_N$.
It follows that a discretization policy $M$ on $X$ can be written as $M_X = \brock{n_1,n_2,\ldots,n_k}$, where $k$, $n_1$, $n_2$, $\ldots,n_k$ are positive integers satisfying $N = \sum_{i=1}^k n_i$.
An optimal discretization policy maximizes $P(M)\cdot P(D\mid M)$ for some prior $P(M)$ and likelihood $P(D\mid M)$.

%Furthermore, since there might have repeated values for $D_x$, we assume there are $N'$ unique values of $D_x$ and $N' \leq N$. Note that the allowable discretization edges happens between two consective values of non-repeated value of $D_x$. For example, if $D_X = \{ 1.0,1.0,2.0\}$, then the only possible discretization edge is on $1.5$.


\subsection{Priors and Objective Function}

We have the following four priors for the discretization model $M$ that enable us to evaluate $P(M)$ and $P(D \mid M)$:\\
\begin{enumerate}
\item For a discretization edge locating at $(x_i + x_{i+1})/2$ has probability
\begin{equation}
1 - {\exp(- L \cdot {{x_{i+1} - x_i}\over{x_N - x_1}})},
\end{equation}
where $L$ is the largest cardinality number of discrete variables in $X$'s Markov blanket.
\item For a given interval of $M$, every distribution of $\Pi_X$ is equiprobable.
\item For each pair of $(C_i,\boldsymbol{S_i})$ and a given interval of $M$, every distribution of $C_i$ with a value of $\boldsymbol{S_i}$ is equiprobable.
\item The distributions of each $C_i$ and $\Pi_X$ in each interval of $M$ with each value of $\boldsymbol{S_i}$ are independent from each other.
\end{enumerate}

Owing to these priors, we are able to evaluate $P(M)$ and $P(D \mid M)$. For the former, we have
\begin{equation}
P(M) = \prod_{i=1}^k \{ [1 - {\exp(- L \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}] \cdot \exp(L \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}}) \},
\end{equation}
where $s_i = \sum_{j=1}^k n_j$ and $s_k = N$, $s_0 = 0$. Before evaluating $P(D \mid M)$, notice that
\begin{equation}
P(D \mid M) \propto P(D_{\Pi_x} \mid M) \cdot \prod_{i = 1}^{n_c} P(D_{C_i} \mid M, D_{\boldsymbol{S_i}}).
\end{equation}
The graph structure allows us to only consider the interations between $X$ and other variables in its Markov blanket and thus leads to the factorization. For example, in Figure 1., the corresponding $P(D \mid M)$ is factorized as
\begin{equation}
P(D_{ P_1,P_2,P_3 } \mid M) \cdot P( D_{ C_1 } \mid M,D_{\boldsymbol{S_1}}) \cdot P(D_{C_2} \mid M,D_{ S_2  }).
\end{equation}

\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph1}
    \end{tabular}
  \caption{Factorization of $P(D \mid M)$}
\end{figure}


The concept behind the factorization is similar to sampling in a Bayesian network. Once we have the distribution of $X$ and sample $X$ for it, then we can further sample $\Pi_x$. Since the samples of $P_1,P_2,\ldots,P_{n_p}$ given a value of $X$ are not independent, we can not further factorize $P(D_{\Pi_x} \mid M)$ into $\prod_i P(D_{P_i} \mid M)$. Similarly, once we have samples of $X$ and $\boldsymbol{S_i}$, we can sample $C_i$. Since the sampling processes of child variables are independent from each other, we have the product $\prod_{i = 1}^{n_c} P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$.\\

For the following part, we evaluate $P(D_{\Pi_x} \mid M)$  and $P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$ based on discretization policy $M = [n_1,n_2,\ldots,n_k]$ and dataset $D$.
\subsubsection{Evaluate $P(D_{\Pi_x} \mid M)$}
Assume that $J_P = \prod_{i=1}^{n_p} | P_i |$. Then we have:
\begin{equation}
P(D_{\Pi_X} \mid M) = \prod_{i=1}^k  {{1}\over{{n_i + J_P - 1}\choose{J_P -1}}}
{{1}\over{ {{{n}_i}!}\over{ {n^{(p)}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_P} !}}  }},
\end{equation}
where $n^{(p)}_{i,j}$ is the number of instances in $i$th discretized interval with $j$th value of $\Pi_X$. Note that $n_i = \sum_{j=1}^{| \Pi_x |} n^{(p)}_{i,j}$. The two factors on RHS comes from the second prior: all distributions of values of $\Pi_X$ in a given interval are equiprobable. According to the forth prior, the distribution in each interval is independent, so we multiply all the two factors together.
\subsubsection{Evaluate $P(D_{C_i} \mid M, D_{\boldsymbol{S_i}})$}
Assume for each pair of $(C_j, \boldsymbol{S_j})$, we have $|C_j | = J_j$ and $| \boldsymbol{S_j} | = L_j = \prod_{v \in \boldsymbol{S_j}} | v |$. Therefore,
\begin{equation}
P(D_{C_j}  \mid M, D_{S_j}) =
\prod_{i=1}^{k} \prod_{l=1}^{L_j} {{1}\over{{n_{i,l} + J_j - 1}\choose{J_j-1}}}
{{1}\over{ {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}}  }},
\end{equation}
where $n^{(j)}_{i,m,l}$ is the number of instances in $i$th interval with $m$th value of $C_j$ and $l$th value of $\boldsymbol{S_j}$, $n_{i,l} = \sum_{m=1}^{J_j} n^{(j)}_{i,m,l}$, and $n_i = \sum_{l=1}^{L_j} n_{i,l}$. The two factors on RHS comes from the third prior: all distribution of values of $C_j$ in a given interval and with a given value of $S_j$ are equiprobable. According to the forth prior, these distributions are independent from each other, therefore we multiply all factors. If $S_j = \emptyset$, then Equation 13. is equivalent to
\begin{equation}
P(D_{C_j}  \mid M) =
\prod_{i=1}^{k}  {{1}\over{{n_{i} + J_j - 1}\choose{J_j-1}}}
{{1}\over{ {{n_{i}}!}\over{ {n^{(j)}_{i,1,\emptyset} !} {n^{(j)}_{i,2,\emptyset} !} \cdots {n^{(j)}_{i,J_j,\emptyset} !}}  }},
\end{equation}
where $n^{(j)}_{i,m,\emptyset}$ is the number of instances in $i$th interval with $m$th value of $C_j$, and $\sum_{m=1}^{J_j} n^{(j)}_{i,m,\emptyset} = n_i$. \\

With Equation 8,9,11,12, and 13, now we are able to write down the objective function. Instead of maximizing $P(M) \cdot P(D|M)$, we minimize its log-inverse for convenience. The objective function is
\begin{equation}
\begin{aligned}
& \sum_{i=1}^{k-1} - \log(1 - {\exp(- L \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}) +  \sum_{i=1}^{k} L \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}} +\\
&  \sum_{j=1}^{n_c} \sum_{i=1}^{k}  \sum_{l=1}^{L_j} \left[  \log{{n_{i,l} + J_j - 1}\choose{J_j-1}} + \log \left( { {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}} } \right) \right] + \\
& \sum_{i=1}^k \left[  \log {{n_{i} + J_P - 1}\choose{J_P-1}} + \log \left( { {{n_i}!}\over{ {n^{(p)}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_p} !}} } \right) \right].
\end{aligned}
\end{equation}
All parameters and variables in the objective function are explained in previous subsections.
\subsection{Algorithm}
\label{algo}
Once the objective function is established, the next problem is how to find a discretization model that minimizes the objective function. Note that the objective function is cumulative on intervals. Therefore, if a partition of continuous variable $X$ into $k$ intervals with lengths $n_1,n_2,\ldots,n_k$ is an optimal discretization policy, then $\{ n_2, n_3,\ldots,n_k \}$ is optimal for the subproblem, i.e., the last $N - n_1$ instances of the dataset which has been sorted in ascending order of $D_X$. With this property, we can adapt dynamical programming to solve this optimization problem.

If there is no repeated value in $D_X$, all middle points of two consecutive values can a discretization edge. If there exists repeated values in $D_X$, only the middle points of two consecutive and different values can be a discretization edge. Assume there are $M$ unique values in $D_X$, then ${D'_X} = \{ x'_1,x'_2,\ldots,x'_M \}$ is the set of unique values of $D_X$ in ascending order. Since $D_X$ is also sorted, let $b = \{ b_0,b_1,b_2,\ldots,b_M \}$ be an increasing sequence of integers such that $b_0 = 0$ and $x_{b_{i-1} + 1} = x_{b_{i-1} + 2} = \ldots = x_{{b_i}} = x'_i$. By this definition, the allowable discretization positions are $d_i = ( x_{b_{i}} + x_{{b_i}+1})/2$ for all $i = 1,2,\ldots,M-1$.

Before doing the dynamical programming, in order to save runtime, we first calculate the following function $h(u,v)$ for a interval $I_q$ starting from $x_{u}$ to $x_{v}$ with all $u$,$v$ satisfying $u \leq v$:
\begin{equation}
\begin{aligned}
h(u,v) &=  \log {{n_{q} + J_P - 1}\choose{J_P-1}} + \log \left( { {{n_q}!}\over{ {n^{(p)}_{q,1} !} {n^{(p)}_{q,2} !} \cdots {n^{(p)}_{q,J_p} !}} } \right) \\
& + \sum_{j=1}^{n_c} \sum_{l=1}^{L_j} \left[  \log{{n_{q,l} + J_j - 1}\choose{J_j-1}} + \log \left( { {{n_{q,l}}!}\over{ {n^{(j)}_{q,1,l} !} {n^{(j)}_{q,2,l} !} \cdots {n^{(j)}_{q,J_j,l} !}} } \right) \right]
\end{aligned}
\end{equation}

The evaluation of function $h(u,v)$ for all $u \leq v$ is summerized in Algorithm 4 in Appendix. The calculation can be done in $\bigo\paren{n_c  {v'_\text{max}} \cdot N^2 + {v'_\text{max}}^{n_p} \cdot N^2}$, where $n_c$ and $n_p$ are the numbers of child and parent variables, respectively, and $v'_\text{max}$ is the largest cardinality of variables that directly connects to $X$. Notice that due to repeated values in $D_X$, for some pairs of $u$ and $v$, the value of $h(u,v)$ might depend on the sorting method of $D_X$ and $D$. However, this does not influence the optimization result, since these pairs of $u$ and $v$ will not form valid intervals.

Now we are able to solve the optimization problem with the objective function in Equation 14. The dynamical programming procedure is shown in Algorithm 1. We have three inputs: $D_X$, the data of continuous variable $X$ in the ascending order, $D$, the data of other variables and sorted according to $D_X$, and $G$, the network structure. The runtime of Algorithm 1 is also $\bigo\paren{n_c  {v'_\text{max}} \cdot N^2 + {v'_\text{max}}^{n_p} \cdot N^2}$, since the dynamical programming procedure does not increase the time complexity beyond the calculation of $h(u,v)$. There are other methods that lead to suboptimal results but runs faster than dynamical programming method. Please refer to \citep{Boulle_2006}.

\begin{algorithm}
\caption{ Discretization of one continuous variable}\label{euclid}
\begin{algorithmic}[5]
\Function{Discretize}{$D_X$, $D$, $G$}
\State
\State $N \leftarrow$ the number of instances
\State $N' \leftarrow$ the number of non-repeated values of $D_X$
\State $H \leftarrow$ an $N \times N$ matrix such that $H[u,v] = h(u,v)$ as Algorithm 4 in Appendix
\State $b \leftarrow$ the increasing sequence of $M$ integers defined in the previous discussion
\State $L \leftarrow$ the largest cardinality over all discrete variables in the Markov blanket
\State $S[u] \leftarrow$ the optimal objective value of a subproblem with instances from $1$ to $u$
\State $M[u] \leftarrow$ the optimal discretization of a subproblem with instances from $1$ to $u$
\State $W[u]  \leftarrow - \log(1 - {\exp(- L \cdot{ {{x_{b(u)+1} - x_{b(u)}}\over{x_N - x_1}})}})$ for $u = 1,2, \ldots,N'-1$ and $L(N') \leftarrow 0$
\State
\For {$v = 1$ to $N'$}
\If {$v = 1$}
\State $S[v] = g \left(1,b[v] \right) + L[v]$
\State $M[v] = \{ ({x_{b[v]} + x_{b[v]+1}}) / 2\}$
\Else
\State $s \leftarrow \infty$ and $boundary \leftarrow \infty$
\For {$u = 1$ to $v$}
\State $s' \leftarrow S[u] + g \left( b[u]+1,b[v] \right) +  {L \cdot {{x_{b[v]} - x_{b[u] + 1}}\over{x_N - x_1}}} + W[v]$
\If {$s' < s$}
\State $s \leftarrow s'$
\State $boundary \leftarrow ({x_{b[u]} + x_{b[u]+1}}) / 2$
\EndIf
\EndFor
\State $S[v] \leftarrow s$
\State $M[v] \leftarrow M[u] \cup \{ boundary\}$
\EndIf
\EndFor
 \State \Return $M$
\EndFunction
\end{algorithmic}
\end{algorithm}


\subsection{Approximation}
\label{approx}
Notice that Algorithm1 leads to the non-polynomial runtime $\bigo\paren{{v'_\text{max}}^{n_p} \cdot N^2}$ in the discretization process. Therefore, we have an empirical approximation to the objective function that can reduce runtime and still preserve the quality of discretization. The approximation is as follows: for the dominator of the last factor in Equation 11, we have
\begin{equation}
{{{{n}_i}!}\over{ {{n^{(p)}}_{i,1} !} {n^{(p)}_{i,2} !} \cdots {n^{(p)}_{i,J_P} !}}} \approx \prod_{r=1}^{n_p} { {{{n}_i}!}\over{ {n^{(p_r)}_{i,1} !} {n^{(p_r)}_{i,2} !} \cdots {n^{(p_r)}_{i,J_{p_r}} !}}},
\end{equation}
where $J_{p_r} = | P_r|$ and ${n^{(p_r)}_{i,j} !}$ is the number of instances in $i$th interval with $j$th value of $P_r$. Applying this approximation, the approximated objective function is
\begin{equation}
\begin{aligned}
& \sum_{i=1}^{k-1} - \log(1 - {\exp(- L \cdot {{x_{s_i+1} - x_{s_i}}\over{x_N - x_1}})}) +  \sum_{i=1}^{k} L \cdot {{x_{s_{i}} - x_{s_{i-1} + 1}}\over{x_N - x_1}} +\\
&  \sum_{j=1}^{n_c} \sum_{i=1}^{k}  \sum_{l=1}^{L_j} \left[  \log{{n_{i,l} + J_j - 1}\choose{J_j-1}} + \log \left( { {{n_{i,l}}!}\over{ {n^{(j)}_{i,1,l} !} {n^{(j)}_{i,2,l} !} \cdots {n^{(j)}_{i,J_j,l} !}} } \right) \right] + \\
& \sum_{i=1}^k \left[  \log {{n_{i} + J_P - 1}\choose{J_P-1}} + \sum_{q=1}^{n_p} \log \left( { {{{n}_i}!}\over{ {n^{(p_q)}_{i,1} !} {n^{(p_q)}_{i,2} !} \cdots {n^{(p_q)}_{i,J_{p_q}} !}}} \right) \right].
\end{aligned}
\end{equation}


As we will see in Section \ref{sec:experiments}, the approximated algorithm is more sensitive to the distribution of other variables' values and usually leads to slightly more discretization edges. With the approximation, we can reduce runtime of Algorithm 1 from $\bigo\paren{n_c  {v'_\text{max}} \cdot N^2 + {v'_\text{max}}^{n_p} \cdot N^2}$ to $\bigo\paren{v'_\text{max} (n_c + n_p) \cdot N^2}$. The rigorous proof of the approximation have not been proposed.

With the approximated objective function, Equation 17, we now have a more clear way to see that how child variables and parent variables contribute to the objective function differently. For example, in the left graph of Figure 2, the corresponding sqaure brackets in Equation 17 are
\begin{equation}
\begin{aligned}
 \sum_{i=1}^k & \left\lbrace   \left[ \log{{n_{i} + J_{C_1} - 1}\choose{J_{C_1}-1}} + \log \left(  {{{n_i}!} \over { {n^{(1)}_{i,1,\emptyset} !} \cdots {n^{(1)}_{i,J_{C_1},\emptyset} !}} }  \right)  +  \right. \right.\\
& \left.  \log{{n_{i} + J_{C_2} - 1}\choose{J_{C_2}-1}} + \log \left(  {{{n_i}!} \over { {n^{(2)}_{i,1,\emptyset} !} \cdots {n^{(2)}_{i,J_{C_1},\emptyset} !}} }  \right)  \right] + \\
&  \left. \left[  \log {{n_{i} + J_P - 1}\choose{J_P-1}} +  \log \left( { {{{n}_i}!}\over{ {n^{(p_1)}_{i,1} !}\cdots {n^{(p_1)}_{i,J_{p_1}} !}}} \right) +{ {{{n}_i}!}\over{ {n^{(p_2}_{i,1} !}\cdots {n^{(p_2)}_{i,J_{p_2}} !}}}  \right] \right\rbrace\\ .
\end{aligned}
\end{equation}


In Equation18, each child variable carries two terms, as shown in the first square bracket, and two parent variables only carry three terms, as shown in the second square bracket. Therefore, in this case, child variables are more determinative than parent variables even though the numbers of child variables and parent variables are equal. However, if $C_2$ has the other parent variable $S_2$, as shown in the right graph of Figure 2, the importances of $C_2$ will be debiliated, since the information from $C_2$ is now adulterated by $S_2$. These argument shows that our proposed method, either before or after approximation, indeed involves graph structures to discretize continuous variables.

\begin{figure}[ht]
    \begin{tabular}{cc}
      \input{graph2_left}
      \end{tabular}
     \hspace{5em}
      \begin{tabular}{cc}
      \input{graph2_right}
    \end{tabular}
  \caption{Two example networks}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Extension to Multiple Continuous Variables}
\label{sec:multi_var}

\subsection{Discretization of Multiple Continuous Variables}

If there are multiple continuous variables in a Bayesian network, we iterate the one-variable discretization method discussed above for all continuous variables. While discretizing a continuous variable, other continuous variables must be discretized, either by a prediscretization that was done before the first iteration or by the discretization result of the latest iteration. The prediscretization can be done by equal-width discretization, which is defined as follows:
\begin{equation}
M_X =  \{ min_X, min_X + \delta, min_X + 2\delta, \ldots, \delta, max_X \},
\end{equation}
where $min_X$ and $max_X$ are minimal and maximal values of $D_X$, respectively, $\delta =  (max_X - min_X)/k$, and $k$ is the desired number of intervals after equal-width discretization. $k$ is same for all continuous variables and is set to be median value of all discrete variables' cardinalities. After prediscretization, we iterate the one-variable discretization on each continuous variable in the following order: from the continuous variable with highest topological order (leaves) to the continuous variable with lowest topological order (root). We call one such series of discretizations as a cycle. The advange of the order is that, for the first cycle of iteration, we can use less number of unsupervised discretization result. For example, in the right graph of Figure 2, assume $S_2$ is the only discrete variable. If we begin the iteration with $P_1$, then the discretization of $P_1$ will involve the prediscretization results of both $P_2$ and $X$. However, if we begin the iteration with $C_1$, then the discretization of $C_1$ will only involve the prediscretization result of $X$.

When the number of intervals after discretization and the positions of discretization edges converge, we stop the iterations and output the discretization policy on each continuous variable. Since the convergence is not guaranteed, we also set up a maximal number of cycles to prevent infinite iterations. In our test on real-world data, the iteration results usually converge within few cycles. Even if it does not converge, 10 cycles usually produce good enough discretization result. The pseudocode of multi-variable discretization is shown in Algorithm 2, where we require four inputs: $D''$, the mixed data of all variables that we plan to learn from, $G$, the network structure, $C$, the set of all continuous variables in a reverse topological order, and $u_{cycle}$, the upper bound of times of cycles.

\begin{algorithm}
\caption{ Discretization of multiple continuous variables}
\begin{algorithmic}[5]
\Function{Discretize}{$D''$, $G$, $C$, $u_{cycle}$}
\State
\State $M[i] \leftarrow$ the discretization policy of $i$th variable
\State $n \leftarrow$ the number of variables in Bayesian network
\State $D^*_i \leftarrow M[i] (D_i)$, the discretized $D_i$ by $M[i]$
\State $D^* \leftarrow $ the discretized data for all variables, where $D^*_i \leftarrow D''_i$ if $i \notin C$
\State $k \leftarrow median\{ |v|, v\notin C\}$
\State
\For {$i = 1$ to $n$}
\If {$i \in C$}
\State $M[i] \leftarrow$  equal-width discretization with $k$ intervals
\State $D^*_i \leftarrow  M[i] (D''_i)$
\EndIf
\EndFor
\State
\State $cycle \leftarrow 0$
\While {$M$ is not converged  \textbf{and} $cycle \leq u_{cycle}$}
\State {$cycle  \leftarrow cycle  + 1$}
\For {$j = 1$ to $|C|$}
\State $D^*_{\backslash C(j)} \leftarrow D^*$ without $D^*_{C(j)}$.
\State {$M[C(j)] \leftarrow $ DISCRETIZE($D_{C(j)}$,$D^*_{ \backslash C(j)}$,graph)}
\State {$D^*_{C(j)}  \leftarrow$ $M[C(j)](D''_{C(j)}) $}
\EndFor
\EndWhile
\State \Return $M$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Discretization of Continuous Variables While Structure Learning}

In many situations the network structure is not known in advance, then we need to learn it from data. We use an alternative approach to combine our proposed discretization method with the K2 structure learning algorithm \citep{K2}. That is to say, we start with some prediscretizations on continuous variables and run the K2 algorithm given the discretized data. Each time an edge is added by the K2 algorithm, we rediscretize the continuous variables based on the current network. Then the new discretization policies update the discretized data of all continuous variables, and we continue the next K2 step with the updated discretized data. This cycle is repeated until no edge is added by the K2 algorithm. The detail of the procedure is shown in Algorithm 3. Here we have five inputs: $D'$, the mixed data we plan to learn from, $C$, the set of all continuous variables, $order$, the variable order which is required by the $K2$, $u_{parent}$, the upper bound of number of parents which is also required by the $K2$, and $u_{cycle}$, the upper bound of times of cycles. Notice that in the usual structure learning from discrete data, one usually run the K2 algorithm many times with different orders, and choose the structure with the highest K2 score. We do the same thing: run Algorithm 3 many times, each time with a different order, and pick the discretized Bayesian network with the highest K2 score.
\begin{algorithm}
\caption{ Learning a discrete-valued Bayesian network}
\begin{algorithmic}[5]
\Function{Learn\_DBN}{$D''$, $C$, $order$, $u_{parent}$, $C$, $u_{cycle}$}
\State

\State $n \leftarrow$ the number of variables in Bayesian network
\State $k \leftarrow median\{ |v|, v\notin C\}$
\State $M[i] \leftarrow$ the discretization policy of $i$th variable
\State $D^*_i \leftarrow M[i] (D_i)$, the discretized $D_i$ by $M[i]$
\State $D^* \leftarrow $ the discretized data for all variables, where $D^*_i \leftarrow D''_i$ if $i \notin C$
\State $G \leftarrow$ the initial graph (no edges between nodes)
\State
\For {$i = 1$ to $n$}
\If {$i \in C$}
\State $M[i] \leftarrow$  equal-width discretization with $k$ intervals
\State $D^*_i \leftarrow  M[i] (D''_i)$
\EndIf
\EndFor
\State
\For {$i =1$ to $n$}
\State $P_{old} \leftarrow f(X^*_i,\Pi_{X^*_i})$: Equation 5
\State OKToProceed $\leftarrow$ \textbf{true}
\While OKToProceed \textbf{and} $|\Pi_{X^*_i}| < u_{parent}$
\State $Y \leftarrow$ an element from the set $order[1:i] \backslash \Pi_X$
\State $P_{new} \leftarrow f(X^*_i,\Pi_{X^*_i} \cup Y)$
\If {$P_{new} > P_{old}$}
\State $P_{old} \leftarrow P_{new}$
\State $\Pi_{X_i} \leftarrow \Pi_{X_i} \cup Y $
\State $M \leftarrow$ {DISCRETIZE}({$D''$, $G$, $C$, $u_{cycle}$}): Algorithm 2
\State $D* = M(D'')$
\Else
\State OKToProceed $\leftarrow$ \textbf{false}
\EndIf
\EndWhile
\EndFor
\State \Return $G$, $M$
\EndFunction
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments}
\label{sec:experiments}



%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
%\begin{thebibliography}{}
\bibliographystyle{spbasic}
\bibliography{my_bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Appendices}

\begin{algorithm}
\caption{ Calculation of function $h(u,v)$ for all $u \leq v$}\label{euclid}
\begin{algorithmic}[1]
\State Initialize $H$ as an $N \times N$ matrix that all elements are 0.
\State $count_p$ is an $N \times N \times |\Pi_X|$ matrix such that $count_p [u,v,w]$ is the number of instances from $x_u$ to $x_v$ with $w$th value of $\Pi_X$. This matrix can be calculated in $\bigo\paren{|\Pi_X| \cdot N^2}$
\For {$u = 1$ to $N$}
\For {$v = u$ to $N$}
\State $H(u,v) \leftarrow H(u,v) + \log((v-u + J_p)!) - \log((J_p -1)!)$
\For {$w = 1$ to $|\Pi_X|$}
\State $H(u,v) \leftarrow H(u,v) - \log( count_p(u,v,w)!)$
\EndFor
\EndFor
\EndFor

\For {$j = 1$ to $n_c$}
\State XXX
\EndFor
\end{algorithmic}
\end{algorithm}

\end{document}
% end of file template.tex

